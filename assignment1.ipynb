{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helpers\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.tree import DecisionTreeClassifier as dtclf\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def balanced_accuracy(truth, pred):\n",
    "    wts = compute_sample_weight('balanced', truth)\n",
    "    return accuracy_score(truth, pred, sample_weight=wts)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy)    \n",
    "\n",
    "# Plots learning curve\n",
    "def plot_learning_curve(title,\n",
    "                        train_sizes,\n",
    "                        train_scores, test_scores, ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=None):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Grid search + learning curve\n",
    "def basicResults(clfObj, trgX, trgY, tstX, tstY, params, clf_type=None, dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    print('Calculating basic results for', dataset)\n",
    "    \n",
    "    # Saves results of hyperparameters grid search\n",
    "    cv = ms.GridSearchCV(clfObj, \n",
    "                         n_jobs=-1, \n",
    "                         param_grid=params,\n",
    "                         verbose=False,\n",
    "                         cv=5, \n",
    "                         scoring=scorer, \n",
    "                         return_train_score=True)\n",
    "    cv.fit(trgX, trgY)\n",
    "    st = time()\n",
    "    cv.best_estimator_.fit(trgX, trgY)\n",
    "    train_time = time() - st\n",
    "    st = time()\n",
    "    cv.predict(trgX[0].reshape(1, -1))\n",
    "    predict_time = time() - st\n",
    "      \n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type, dataset), index=False)\n",
    "    train_score = cv.score(trgX, trgY)\n",
    "    test_score = cv.score(tstX, tstY)\n",
    "    \n",
    "    # Saves best iteration   \n",
    "    results = pd.DataFrame({'classifier': [clf_type],\n",
    "                 'dataset': [dataset],\n",
    "                 'train_score': [train_score],\n",
    "                 'test_score': [test_score],\n",
    "                 'train_time': [train_time],\n",
    "                 'predict_time': [predict_time],\n",
    "                 'params': [cv.best_params_]})\n",
    "    \n",
    "    results.to_csv('./output/{}_{}_best.csv'.format(clf_type, dataset))\n",
    "    \n",
    "    # Saves learning curve\n",
    "    N = trgY.shape[0]\n",
    "    train_sizes = [50,100]+[int(N*x/10) for x in range(1,8)]\n",
    "    np.random.seed(55)\n",
    "    curve = ms.learning_curve(cv.best_estimator_,\n",
    "                              trgX, trgY,\n",
    "                              cv=5,\n",
    "                              train_sizes=train_sizes,\n",
    "                              verbose=False,\n",
    "                              scoring=scorer)\n",
    "\n",
    "    curve_train_scores = pd.DataFrame(index=curve[0], data=curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index=curve[0], data=curve[2])\n",
    "    \n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type, dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type, dataset))\n",
    "    \n",
    "    plt = plot_learning_curve('Learning Curve: {} - {}'.format(clf_type, dataset),\n",
    "                        train_sizes,\n",
    "                        curve_train_scores, curve_test_scores, ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=None)\n",
    "    \n",
    "    plt.savefig('./output/images/{}_{}_LC.png'.format(clf_type, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return cv\n",
    "\n",
    "def iterationLC(clfObj, trgX, trgY, tstX, tstY, params, clf_type=None, dataset=None):\n",
    "    print('Calculating iteration learning curve for ',dataset)\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name: value})\n",
    "        clfObj.fit(trgX, trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY, pred))\n",
    "        clfObj.fit(trgX, trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY, pred))\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/{}_{}_ILC.csv'.format(clf_type, dataset), index=False)\n",
    "    return\n",
    "    \n",
    "def add_noise(y, frac=0.1):\n",
    "    np.random.seed(456)\n",
    "    n = y.shape[0]\n",
    "    sz = int(n*frac)\n",
    "    ind = np.random.choice(np.arange(n),size=sz,replace=False)\n",
    "    tmp = y.copy()\n",
    "    tmp[ind] = 1-tmp[ind]\n",
    "    return tmp\n",
    "\n",
    "# Timing curve\n",
    "def plot_timing_curve(title, data_sizes, fit_times, predict_times, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Testing Size (% of total)\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    predict_times_mean = np.mean(predict_times, axis=1)\n",
    "    predict_times_std = np.std(predict_times, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(data_sizes, fit_times_mean - fit_times_std,\n",
    "                     fit_times_mean + fit_times_std, alpha=0.2)\n",
    "    plt.fill_between(data_sizes, predict_times_mean - predict_times_std,\n",
    "                     predict_times_mean + predict_times_std, alpha=0.2)\n",
    "    plt.plot(data_sizes, predict_times_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Predict time\")\n",
    "    plt.plot(data_sizes, fit_times_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Fit time\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_timing_curve(X, Y, clf, clf_name, dataset):\n",
    "    out = defaultdict(dict)\n",
    "    print('Making timing curve for', dataset)\n",
    "    fracs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    for frac in fracs:  \n",
    "        X_train, X_test, y_train, y_test = ms.train_test_split(X, Y, test_size=frac, random_state=42)\n",
    "        st = time()\n",
    "        np.random.seed(55)\n",
    "        clf.fit(X_train, y_train)\n",
    "        out['train'][frac]= time() - st\n",
    "        st = time()\n",
    "        clf.predict(X_test)\n",
    "        out['test'][frac]= time() - st\n",
    "    out = pd.DataFrame(out)\n",
    "    out.to_csv('./output/{}_{}_timing.csv'.format(clf_name, dataset))\n",
    "    train_df = pd.DataFrame(out['train'], index=fracs)\n",
    "    test_df = pd.DataFrame(out['test'], fracs)\n",
    "    plt = plot_timing_curve('Timing Curve: {} - {}'.format(clf_name, dataset),\n",
    "                            np.array(fracs) * 100, \n",
    "                            train_df, test_df)\n",
    "    \n",
    "    plt.savefig('./output/images/{}_{}_TC.png'.format(clf_name, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_complexity_curve(title, param, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    best = pd.read_csv('./output/{}_{}_best.csv'.format(classifier, dataset))\n",
    "    best_params = ast.literal_eval(best.loc[0, 'params'])\n",
    "    grid_search = pd.read_csv('./output/{}_{}_reg.csv'.format(classifier, dataset))\n",
    "    best_params.pop('{}__{}'.format(classifier, param))\n",
    "    for _param, value in best_params.items():\n",
    "        if isinstance(value, tuple):\n",
    "            grid_search['param_'+_param] = grid_search['param_'+_param].apply(ast.literal_eval)\n",
    "        grid_search = grid_search.loc[grid_search['param_'+_param] == value]\n",
    "    df = grid_search[['param_{}__{}'.format(classifier, param), \n",
    "                      'mean_test_score', \n",
    "                      'std_test_score', \n",
    "                      'mean_train_score', \n",
    "                      'std_train_score']].sort_values(by='param_{}__{}'.format(classifier, param))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores_mean = df['mean_train_score']\n",
    "    train_scores_std = df['std_train_score']\n",
    "    test_scores_mean = df['mean_test_score']\n",
    "    test_scores_std = df['std_test_score']\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(param_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2)\n",
    "    plt.fill_between(param_values, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2)\n",
    "    plt.plot(param_values, train_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_complexity_curve(clf_name, dataset, param):    \n",
    "    print('Making complexity curve for', dataset)\n",
    "    plt = plot_complexity_curve('Complexity Curve: {} - {} - {}'.format(clf_name, dataset, param),\n",
    "                                param,\n",
    "                                clf_name,\n",
    "                                dataset,\n",
    "                                ylim=None)\n",
    "\n",
    "    plt.savefig('./output/images/{}_{}_CC_{}.png'.format(clf_name, dataset, param), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_iteration_learning_curve(title, param, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    df = pd.read_csv('./output/{}_{}_ILC.csv'.format(classifier, dataset))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores = df['train acc']\n",
    "    test_scores = df['test acc']\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.plot(param_values, train_scores, \n",
    "             'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores, \n",
    "             'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_iteration_learning_curve(clf_name, dataset, param):    \n",
    "    print('Making iteration learning curve for', dataset)\n",
    "    plt = plot_iteration_learning_curve('Iteration Learning Curve: {} - {}'.format(clf_name, dataset),\n",
    "                                        param,\n",
    "                                        clf_name,\n",
    "                                        dataset,\n",
    "                                        ylim=None)\n",
    "\n",
    "    plt.savefig('./output/images/{}_{}_ILC.png'.format(clf_name, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "# Modified decision tree classifier that performs post-pruning\n",
    "class dtclf_pruned(dtclf):        \n",
    "    def remove_subtree(self,root):\n",
    "        '''Clean up'''\n",
    "        tree = self.tree_\n",
    "        visited,stack= set(),[root]\n",
    "        while stack:\n",
    "            v = stack.pop()\n",
    "            visited.add(v)\n",
    "            left =tree.children_left[v]\n",
    "            right=tree.children_right[v]\n",
    "            if left >=0:\n",
    "                stack.append(left)\n",
    "            if right >=0:\n",
    "                stack.append(right)\n",
    "        for node in visited:\n",
    "            tree.children_left[node] = -1\n",
    "            tree.children_right[node] = -1\n",
    "        return \n",
    "        \n",
    "    def prune(self):      \n",
    "        C = 1-self.alpha\n",
    "        if self.alpha <= -1: # Early exit\n",
    "            return self\n",
    "        tree = self.tree_        \n",
    "        bestScore = self.score(self.valX,self.valY)        \n",
    "        candidates = np.flatnonzero(tree.children_left>=0)\n",
    "        for candidate in reversed(candidates): # Go backwards/leaves up\n",
    "            if tree.children_left[candidate]==tree.children_right[candidate]: # leaf node. Ignore\n",
    "                continue\n",
    "            left = tree.children_left[candidate]\n",
    "            right = tree.children_right[candidate]\n",
    "            tree.children_left[candidate]=tree.children_right[candidate]=-1            \n",
    "            score = self.score(self.valX,self.valY)\n",
    "            if score >= C*bestScore:\n",
    "                bestScore = score                \n",
    "                self.remove_subtree(candidate)\n",
    "            else:\n",
    "                tree.children_left[candidate]=left\n",
    "                tree.children_right[candidate]=right\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return self\n",
    "        \n",
    "    def fit(self,X,Y,sample_weight=None,check_input=True, X_idx_sorted=None):        \n",
    "        if sample_weight is None:\n",
    "            sample_weight = np.ones(X.shape[0]) \n",
    "        self.trgX = X.copy()\n",
    "        self.trgY = Y.copy()\n",
    "        self.trgWts = sample_weight.copy()        \n",
    "        sss = ms.StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=123)\n",
    "        for train_index, test_index in sss.split(self.trgX,self.trgY):\n",
    "            self.valX = self.trgX[test_index]\n",
    "            self.valY = self.trgY[test_index]\n",
    "            self.trgX = self.trgX[train_index]\n",
    "            self.trgY = self.trgY[train_index]\n",
    "            self.valWts = sample_weight[test_index]\n",
    "            self.trgWts = sample_weight[train_index]\n",
    "        super().fit(self.trgX,self.trgY,self.trgWts,check_input,X_idx_sorted)\n",
    "        self.prune()\n",
    "        return self\n",
    "    def __init__(self,\n",
    "                 criterion=\"gini\",\n",
    "                 splitter=\"best\",\n",
    "                 max_depth=None,\n",
    "                 min_samples_split=2,\n",
    "                 min_samples_leaf=1,\n",
    "                 min_weight_fraction_leaf=0.,\n",
    "                 max_features=None,\n",
    "                 random_state=None,\n",
    "                 max_leaf_nodes=None,\n",
    "                 min_impurity_decrease=1e-7,\n",
    "                 class_weight=None,\n",
    "                 presort=False,\n",
    "                 alpha = 0):\n",
    "        super(dtclf_pruned, self).__init__(\n",
    "            criterion=criterion,\n",
    "            splitter=splitter,\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_features=max_features,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            class_weight=class_weight,\n",
    "            random_state=random_state,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            presort=presort)\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def numNodes(self):\n",
    "        assert (self.tree_.children_left>=0).sum() == (self.tree_.children_right>=0).sum() \n",
    "        return  (self.tree_.children_left>=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8124, 23)\n",
      "Mushroom types:  Index(['e', 'p'], dtype='object')\n",
      "Labels balance: \n",
      " e    0.517971\n",
      "p    0.482029\n",
      "Name: type_label, dtype: float64\n",
      "Missing values for stalk root: 2480\n"
     ]
    }
   ],
   "source": [
    "# Data load and preprocessing\n",
    "\n",
    "# Mushroom dataset\n",
    "mushroom = pd.read_csv('mushroom.txt', header=None)\n",
    "print('Dataset shape: ' + str(mushroom.shape))\n",
    "mushroom.columns = ['type', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color','population', 'habitat']\n",
    "mushroom['type_label'] = mushroom['type'].astype('category')\n",
    "print('Mushroom types: ', str(mushroom['type_label'].cat.categories))\n",
    "print('Labels balance: \\n', mushroom['type_label'].value_counts()/mushroom['type_label'].size)\n",
    "# Code 1 is for poisonous mushrooms\n",
    "\n",
    "mushroom['type'] = mushroom['type_label'].cat.codes\n",
    "\n",
    "# There are no null values, missing is represented as ? only for stalk root\n",
    "print('Missing values for stalk root: '+ str(sum(mushroom['stalk-root']=='?')))\n",
    "\n",
    "# We remove feature stalk-root due to high number of missing values\n",
    "mushroom = pd.get_dummies(mushroom.drop(columns=['type_label','stalk-root']))\n",
    "mushroom = mushroom.astype(float)\n",
    "mushroom.type = mushroom.type.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (4898, 12)\n",
      "Quality values:  Index(['bad', 'good'], dtype='object')\n",
      "Labels balance: \n",
      " bad     0.783585\n",
      "good    0.216415\n",
      "Name: quality_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Wine dataset\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';')\n",
    "print('Dataset shape: ', str(wine.shape))\n",
    "\n",
    "# There are no null values in the dataset\n",
    "\n",
    "# Creation of class for good vs bad wines (good when greater or equal than 7)\n",
    "wine['quality_label'] = 'bad'\n",
    "wine.loc[wine['quality']>=7, 'quality_label'] = 'good'\n",
    "wine['quality_label'] = wine['quality_label'].astype('category')\n",
    "\n",
    "print('Quality values: ', str(wine['quality_label'].cat.categories))\n",
    "print('Labels balance: \\n', wine['quality_label'].value_counts()/wine['quality_label'].size)\n",
    "\n",
    "wine['quality_int'] = wine['quality']\n",
    "wine['quality'] = wine['quality_label'].cat.codes\n",
    "\n",
    "wine = wine.drop(['quality_label', 'quality_int'], axis=1)\n",
    "wine = wine.astype(float)\n",
    "wine.quality = wine.quality.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data       \n",
    "mushroomX = mushroom.drop('type', axis=1).values\n",
    "mushroomY = mushroom['type'].values\n",
    "\n",
    "wineX = wine.drop('quality', axis=1).values\n",
    "wineY = wine['quality'].values\n",
    "\n",
    "mushroom_trgX, mushroom_tstX, mushroom_trgY, mushroom_tstY = ms.train_test_split(mushroomX, mushroomY, test_size=0.3, random_state=0, stratify=mushroomY)     \n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = ms.train_test_split(wineX, wineY, test_size=0.3, random_state=0, stratify=wineY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for mushroom\n",
      "Calculating basic results for wine\n",
      "Making complexity curve for mushroom\n",
      "Making complexity curve for wine\n",
      "Making timing curve for mushroom\n",
      "Making timing curve for wine\n",
      "Dumping table of pruning vs nodes mushroom\n",
      "Dumping table of pruning vs nodes wine\n"
     ]
    }
   ],
   "source": [
    "# Decision trees\n",
    "\n",
    "def DTpruningVSnodes(clf, alphas, trgX, trgY, dataset):\n",
    "    '''Dump table of pruning alpha vs. # of internal nodes'''\n",
    "    print('Dumping table of pruning vs nodes', dataset)\n",
    "    out = {}\n",
    "    for a in alphas:\n",
    "        clf.set_params(**{'DT__alpha':a})\n",
    "        clf.fit(trgX,trgY)\n",
    "        out[a]=clf.steps[-1][-1].numNodes()\n",
    "    out = pd.Series(out)\n",
    "    out.index.name='alpha'\n",
    "    out.name = 'Number of Internal Nodes'\n",
    "    out.to_csv('./output/DT_{}_nodecounts.csv'.format(dataset))    \n",
    "    return\n",
    "\n",
    "# Search for good alphas\n",
    "alphas = [-0.007 + 0.001*(i+1) for i in range(10)]\n",
    "\n",
    "pipeM = Pipeline([('DT', dtclf_pruned(random_state=55))])\n",
    "\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),                 \n",
    "                 ('DT', dtclf_pruned(random_state=55))])\n",
    "\n",
    "params = {'DT__criterion':['gini', 'entropy'], \n",
    "          'DT__alpha': alphas}\n",
    "\n",
    "mushroom_clf = basicResults(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "                            params,'DT','mushroom')        \n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params, 'DT', 'wine')\n",
    "\n",
    "mushroom_final_params = mushroom_clf.best_params_\n",
    "wine_final_params = wine_clf.best_params_\n",
    "make_complexity_curve('DT', 'mushroom', 'alpha')\n",
    "make_complexity_curve('DT', 'wine', 'alpha')\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "make_timing_curve(mushroomX, mushroomY, pipeM, 'DT', 'mushroom')\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'DT', 'wine')\n",
    "\n",
    "DTpruningVSnodes(pipeM, alphas, mushroom_trgX, mushroom_trgY, 'mushroom')\n",
    "DTpruningVSnodes(pipeW, alphas, wine_trgX, wine_trgY, 'wine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for mushroom\n",
      "Calculating basic results for wine\n",
      "Making complexity curve for mushroom\n",
      "Making complexity curve for wine\n",
      "Making complexity curve for mushroom\n",
      "Making complexity curve for wine\n",
      "Making timing curve for mushroom\n",
      "Making timing curve for wine\n"
     ]
    }
   ],
   "source": [
    "# boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "alphas = [-0.007 + 0.001*(i+1) for i in range(10)]\n",
    "\n",
    "mushroom_base = dtclf_pruned(criterion='gini', class_weight='balanced', random_state=55)                \n",
    "wine_base = dtclf_pruned(criterion='entropy', class_weight='balanced', random_state=55)\n",
    "\n",
    "paramsM= {'Boost__n_estimators': [1, 2, 5, 10, 20, 30, 45, 60, 80, 100],\n",
    "          'Boost__base_estimator__alpha': alphas}\n",
    "\n",
    "paramsW = {'Boost__n_estimators': [1, 2, 5, 10, 20, 30, 45, 60, 80, 100],\n",
    "           'Boost__base_estimator__alpha': alphas}\n",
    "                                   \n",
    "         \n",
    "mushroom_booster = AdaBoostClassifier(algorithm='SAMME', \n",
    "                                      learning_rate=1, \n",
    "                                      base_estimator=mushroom_base, \n",
    "                                      random_state=55)\n",
    "\n",
    "wine_booster = AdaBoostClassifier(algorithm='SAMME', \n",
    "                                  learning_rate=1, \n",
    "                                  base_estimator=wine_base, \n",
    "                                  random_state=55)\n",
    "\n",
    "pipeM = Pipeline([('Boost', mushroom_booster)])\n",
    "\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),                \n",
    "                 ('Boost', wine_booster)])\n",
    "\n",
    "mushroom_clf = basicResults(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "                            paramsM, 'Boost', 'mushroom') \n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        paramsW, 'Boost', 'wine')        \n",
    "\n",
    "mushroom_final_params = mushroom_clf.best_params_\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "make_complexity_curve('Boost', 'mushroom', 'n_estimators')\n",
    "make_complexity_curve('Boost', 'wine', 'n_estimators')\n",
    "make_complexity_curve('Boost', 'mushroom', 'base_estimator__alpha')\n",
    "make_complexity_curve('Boost', 'wine', 'base_estimator__alpha')\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(mushroomX, mushroomY, pipeM, 'Boost', 'mushroom')\n",
    "make_timing_curve(wineX, wineY, pipeW, 'Boost', 'wine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for mushroom\n",
      "Calculating basic results for wine\n",
      "Making complexity curve for mushroom\n",
      "Making complexity curve for wine\n",
      "Making timing curve for mushroom\n",
      "Making timing curve for wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "32\n",
      "64\n",
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "Making iteration learning curve for mushroom\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (4) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (8) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (16) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (32) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (64) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (128) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (128) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "256\n",
      "512\n",
      "1024\n",
      "2048\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "Making iteration learning curve for wine\n"
     ]
    }
   ],
   "source": [
    "#Neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pipeM = Pipeline([('MLP', MLPClassifier(max_iter=2000, \n",
    "                                        early_stopping=True, \n",
    "                                        random_state=55))])\n",
    "\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                 ('MLP', MLPClassifier(max_iter=2000,\n",
    "                                       early_stopping=True, \n",
    "                                       random_state=55))])\n",
    "\n",
    "d = wineX.shape[1]\n",
    "hiddens_wine = [(h,)*l for l in [1,2] for h in [d,d//2,d*2]]\n",
    "alphas = [10**-x for x in np.arange(-1,5.01,1/2)]\n",
    "alphasM = [10**-x for x in np.arange(-1,9.01,1/2)]\n",
    "\n",
    "d = mushroomX.shape[1]\n",
    "d = d//(2**4)\n",
    "hiddens_mushroom = [(h,)*l for l in [1,2] for h in [d,d//2,d*2]]\n",
    "\n",
    "params_wine = {'MLP__activation': ['relu', 'logistic'], \n",
    "               'MLP__alpha': alphas, \n",
    "               'MLP__hidden_layer_sizes': hiddens_wine}\n",
    "\n",
    "params_mushroom = {'MLP__activation': ['relu', 'logistic'], \n",
    "                   'MLP__alpha': alphas, \n",
    "                   'MLP__hidden_layer_sizes': hiddens_mushroom}\n",
    "\n",
    "mushroom_clf = basicResults(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "                            params_mushroom, 'MLP', 'mushroom')  \n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'MLP', 'wine')        \n",
    "# print(wine_clf.best_estimator_.named_steps['MLP'].n_iter_)\n",
    "\n",
    "make_complexity_curve('MLP', 'mushroom', 'alpha')\n",
    "make_complexity_curve('MLP', 'wine', 'alpha')\n",
    "\n",
    "mushroom_final_params = mushroom_clf.best_params_\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "make_timing_curve(mushroomX, mushroomY, pipeM, 'MLP', 'mushroom')\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'MLP', 'wine')\n",
    "\n",
    "pipeM.set_params(**{'MLP__early_stopping': False})               \n",
    "iterationLC(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "            {'MLP__max_iter': [2**x for x in range(12)] + [2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000]}, \n",
    "            'MLP', 'mushroom')\n",
    "make_iteration_learning_curve('MLP', 'mushroom', 'max_iter')\n",
    "\n",
    "pipeW.set_params(**{'MLP__early_stopping': False})    \n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'MLP__max_iter': [2**x for x in range(12)] + [2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000]}, \n",
    "            'MLP', 'wine')\n",
    "make_iteration_learning_curve('MLP', 'wine', 'max_iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for mushroom\n",
      "Calculating basic results for wine\n",
      "Making complexity curve for mushroom\n",
      "Making complexity curve for wine\n",
      "Making timing curve for mushroom\n",
      "Making timing curve for wine\n",
      "Calculating iteration learning curve for  mushroom\n",
      "Making iteration learning curve for mushroom\n",
      "Calculating iteration learning curve for  wine\n",
      "Making iteration learning curve for wine\n",
      "Calculating basic results for mushroom\n",
      "Calculating basic results for wine\n",
      "Making complexity curve for mushroom\n",
      "Making complexity curve for wine\n",
      "Making timing curve for mushroom\n",
      "Making timing curve for wine\n",
      "Calculating iteration learning curve for  mushroom\n",
      "Making iteration learning curve for mushroom\n",
      "Calculating iteration learning curve for  wine\n",
      "Making iteration learning curve for wine\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "class primalSVM_RBF(BaseEstimator, ClassifierMixin):\n",
    "    '''http://scikit-learn.org/stable/developers/contributing.html'''\n",
    "    \n",
    "    def __init__(self, alpha=1e-9, gamma_frac=0.1, max_iter=2000):\n",
    "         self.alpha = alpha\n",
    "         self.gamma_frac = gamma_frac\n",
    "         self.max_iter = max_iter\n",
    "         \n",
    "    def fit(self, X, y):\n",
    "         # Check that X and y have correct shape\n",
    "         X, y = check_X_y(X, y)\n",
    "         \n",
    "         # Get the kernel matrix\n",
    "         dist = euclidean_distances(X, squared=True)\n",
    "         median = np.median(dist) \n",
    "         del dist\n",
    "         gamma = median\n",
    "         gamma *= self.gamma_frac\n",
    "         self.gamma = 1/gamma\n",
    "         kernels = rbf_kernel(X, None, self.gamma)    \n",
    "         self.X_ = X\n",
    "         self.classes_ = unique_labels(y)\n",
    "         self.kernels_ = kernels\n",
    "         self.y_ = y\n",
    "         self.clf = SGDClassifier(loss='hinge', penalty='l2', alpha=self.alpha,\n",
    "                                  l1_ratio=0, fit_intercept=True, verbose=False,\n",
    "                                  average=False, learning_rate='optimal',\n",
    "                                  class_weight='balanced', max_iter=self.max_iter,\n",
    "                                  random_state=55)         \n",
    "         self.clf.fit(self.kernels_, self.y_)\n",
    "         \n",
    "         # Return the classifier\n",
    "         return self\n",
    "\n",
    "    def predict(self, X):\n",
    "         # Check is fit had been called\n",
    "         check_is_fitted(self, ['X_', 'y_','clf','kernels_'])\n",
    "         # Input validation\n",
    "         X = check_array(X)\n",
    "         new_kernels = rbf_kernel(X, self.X_, self.gamma)\n",
    "         pred = self.clf.predict(new_kernels)\n",
    "         return pred\n",
    "\n",
    "N_wine = wine_trgX.shape[0]\n",
    "N_mushroom = mushroom_trgX.shape[0]\n",
    "alphas = [10**-x for x in np.arange(1, 9.01, 1/2)]\n",
    "\n",
    "#Linear SVM\n",
    "svm_mushroom = SGDClassifier(loss='hinge',\n",
    "                             l1_ratio=0,\n",
    "                             penalty='l2',\n",
    "                             class_weight='balanced',\n",
    "                             random_state=55,\n",
    "                             tol=None,\n",
    "                             max_iter=1000)\n",
    "\n",
    "svm_wine = SGDClassifier(loss='hinge',\n",
    "                         l1_ratio=0,\n",
    "                         penalty='l2',\n",
    "                         class_weight='balanced',\n",
    "                         random_state=55,\n",
    "                         tol=None,\n",
    "                         max_iter=1000)\n",
    "\n",
    "pipeM = Pipeline([('SVM_Lin', svm_mushroom)])\n",
    "\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),                \n",
    "                ('SVM_Lin', svm_wine)])\n",
    "\n",
    "params_mushroom = {'SVM_Lin__alpha': alphas, \n",
    "                   'SVM_Lin__max_iter': [int(1e6/N_mushroom)]}\n",
    "\n",
    "params_wine = {'SVM_Lin__alpha': alphas, \n",
    "               'SVM_Lin__max_iter': [int(1e6/N_wine)]}\n",
    "                                                 \n",
    "mushroom_clf = basicResults(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "                            params_mushroom, 'SVM_Lin', 'mushroom') \n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'SVM_Lin', 'wine')\n",
    "\n",
    "make_complexity_curve('SVM_Lin', 'mushroom', 'alpha')\n",
    "make_complexity_curve('SVM_Lin', 'wine', 'alpha')\n",
    "\n",
    "mushroom_final_params = mushroom_clf.best_params_\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "make_timing_curve(mushroomX, mushroomY, pipeM, 'SVM_Lin', 'mushroom')\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'SVM_Lin', 'wine')\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "iterationLC(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "            {'SVM_Lin__max_iter': [30*(x+1) for x in range(8)]}, \n",
    "            'SVM_Lin', 'mushroom')  \n",
    "make_iteration_learning_curve('SVM_Lin', 'mushroom', 'max_iter')\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'SVM_Lin__max_iter': [50*(x+1) for x in range(8)]}, \n",
    "            'SVM_Lin', 'wine')\n",
    "make_iteration_learning_curve('SVM_Lin', 'wine', 'max_iter')\n",
    "\n",
    "#RBF SVM\n",
    "\n",
    "gamma_fracsM = np.arange(0.05, 1.01, 0.1)\n",
    "gamma_fracsW = np.arange(0.2, 2.1, 0.2)\n",
    "\n",
    "pipeM = Pipeline([('SVM_RBF', primalSVM_RBF())])\n",
    "\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                 ('SVM_RBF', primalSVM_RBF())])\n",
    "\n",
    "params_mushroom = {'SVM_RBF__alpha': alphas, \n",
    "                   'SVM_RBF__max_iter': [int(1e6/N_mushroom)],\n",
    "                   'SVM_RBF__gamma_frac': gamma_fracsM}\n",
    "\n",
    "params_wine = {'SVM_RBF__alpha': alphas, \n",
    "               'SVM_RBF__max_iter': [int(1e6/N_wine)],\n",
    "               'SVM_RBF__gamma_frac': gamma_fracsW}\n",
    "                                            \n",
    "mushroom_clf = basicResults(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "                            params_mushroom, 'SVM_RBF', 'mushroom')\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'SVM_RBF', 'wine')        \n",
    "\n",
    "mushroom_final_params = mushroom_clf.best_params_\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "make_complexity_curve('SVM_RBF', 'mushroom', 'alpha')\n",
    "make_complexity_curve('SVM_RBF', 'wine', 'alpha')\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)                     \n",
    "make_timing_curve(mushroomX, mushroomY, pipeM, 'SVM_RBF', 'mushroom')\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'SVM_RBF', 'wine')\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "iterationLC(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "            {'SVM_RBF__max_iter': [30*(x+1) for x in range(8)]}, \n",
    "            'SVM_RBF', 'mushroom')\n",
    "make_iteration_learning_curve('SVM_RBF', 'mushroom', 'max_iter')\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'SVM_RBF__max_iter': [50*(x+1) for x in range(8)]},\n",
    "            'SVM_RBF', 'wine')\n",
    "make_iteration_learning_curve('SVM_RBF', 'wine', 'max_iter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for mushroom\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ab3e8bfb8a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mparams_wine\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'KNN__metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'manhattan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chebyshev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KNN__n_neighbors'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KNN__weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmushroom_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasicResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmushroom_trgX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmushroom_trgY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmushroom_tstX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmushroom_tstY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_mushroom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mushroom'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mwine_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasicResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_trgX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_trgY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_tstX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine_tstY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_wine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'KNN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wine'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-aa4f7ef64c3a>\u001b[0m in \u001b[0;36mbasicResults\u001b[0;34m(clfObj, trgX, trgY, tstX, tstY, params, clf_type, dataset)\u001b[0m\n\u001b[1;32m     70\u001b[0m                          \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                          return_train_score=True)\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrgX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrgX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# knn\n",
    "from sklearn.neighbors import KNeighborsClassifier as knnC\n",
    "\n",
    "pipeM = Pipeline([('KNN', knnC())])  \n",
    "\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),                \n",
    "                 ('KNN', knnC())])  \n",
    "\n",
    "params_mushroom= {'KNN__metric': ['manhattan', 'euclidean', 'chebyshev'], \n",
    "                  'KNN__n_neighbors': np.arange(1,51,3), \n",
    "                  'KNN__weights': ['uniform', 'distance']}\n",
    "\n",
    "params_wine= {'KNN__metric': ['manhattan', 'euclidean', 'chebyshev'], \n",
    "              'KNN__n_neighbors': np.arange(1,51,3), \n",
    "              'KNN__weights': ['uniform', 'distance']}\n",
    "\n",
    "mushroom_clf = basicResults(pipeM, mushroom_trgX, mushroom_trgY, mushroom_tstX, mushroom_tstY, \n",
    "                            params_mushroom, 'KNN', 'mushroom')        \n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'KNN', 'wine')        \n",
    "\n",
    "make_complexity_curve('KNN', 'mushroom', 'n_neighbors')\n",
    "make_complexity_curve('KNN', 'wine', 'n_neighbors')\n",
    "\n",
    "mushroom_final_params = mushroom_clf.best_params_\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeM.set_params(**mushroom_final_params)\n",
    "make_timing_curve(mushroomX, mushroomY, pipeM, 'KNN', 'mushroom')\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'KNN', 'wine')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
