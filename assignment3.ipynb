{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from itertools import product\n",
    "from time import clock\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy.sparse as sps\n",
    "from scipy.linalg import pinv\n",
    "from scipy.spatial import distance \n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.cluster import KMeans as kmeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami, accuracy_score as accuracy, pairwise_distances\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def cluster_acc(Y, clusterLabels):\n",
    "    assert (Y.shape == clusterLabels.shape)\n",
    "    pred = np.empty_like(Y)\n",
    "    for label in set(clusterLabels):\n",
    "        mask = clusterLabels == label\n",
    "        sub = Y[mask]\n",
    "        target = Counter(sub).most_common(1)[0][0]\n",
    "        pred[mask] = target\n",
    "#    assert max(pred) == max(Y)\n",
    "#    assert min(pred) == min(Y)    \n",
    "    return accuracy(Y, pred)\n",
    "\n",
    "\n",
    "class myGMM(GMM):\n",
    "    def transform(self, X):\n",
    "        return self.predict_proba(X)\n",
    "        \n",
    "        \n",
    "def pairwiseDistCorr(X1, X2):\n",
    "    assert X1.shape[0] == X2.shape[0]\n",
    "    \n",
    "    d1 = pairwise_distances(X1)\n",
    "    d2 = pairwise_distances(X2)\n",
    "    return np.corrcoef(d1.ravel(), d2.ravel())[0,1]\n",
    "\n",
    "    \n",
    "def aveMI(X, Y):    \n",
    "    MI = MIC(X, Y) \n",
    "    return np.nanmean(MI)\n",
    "    \n",
    "  \n",
    "def reconstructionError(projections, X):\n",
    "    W = projections.components_\n",
    "    if sps.issparse(W):\n",
    "        W = W.todense()\n",
    "    p = pinv(W)\n",
    "    reconstructed = ((p@W)@(X.T)).T # Unproject projected data\n",
    "    errors = np.square(X-reconstructed)\n",
    "    return np.nanmean(errors)\n",
    "    \n",
    "# http://datascience.stackexchange.com/questions/6683/feature-selection-using-feature-importances-in-random-forests-with-scikit-learn          \n",
    "class ImportanceSelect(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, n=1):\n",
    "         self.model = model\n",
    "         self.n = n\n",
    "    def fit(self, *args, **kwargs):\n",
    "         self.model.fit(*args, **kwargs)\n",
    "         return self\n",
    "    def transform(self, X):\n",
    "         return X[:,self.model.feature_importances_.argsort()[::-1][:self.n]]\n",
    "                  \n",
    "#http://stats.stackexchange.com/questions/90769/using-bic-to-estimate-the-number-of-k-in-kmeans    \n",
    "def compute_bic(kmeans, X):\n",
    "    \"\"\"\n",
    "    Computes the BIC metric for a given clusters\n",
    "    Parameters:\n",
    "    -----------------------------------------\n",
    "    kmeans:  List of clustering object from scikit learn\n",
    "    X     :  multidimension np array of data points\n",
    "    Returns:\n",
    "    -----------------------------------------\n",
    "    BIC value\n",
    "    \"\"\"\n",
    "    # assign centers and labels\n",
    "    centers = [kmeans.cluster_centers_]\n",
    "    labels  = kmeans.labels_\n",
    "    #number of clusters\n",
    "    m = kmeans.n_clusters\n",
    "    # size of the clusters\n",
    "    n = np.bincount(labels)\n",
    "    #size of data set\n",
    "    N, d = X.shape\n",
    "\n",
    "    #compute variance for all clusters beforehand\n",
    "    cl_var = (1.0 / (N - m) / d) * sum([sum(distance.cdist(X[np.where(labels == i)], [centers[0][i]], 'euclidean')**2) for i in range(m)])\n",
    "\n",
    "    const_term = 0.5 * m * np.log(N) * (d+1)\n",
    "\n",
    "    BIC = np.sum([n[i] * np.log(n[i]) -\n",
    "               n[i] * np.log(N) -\n",
    "             ((n[i] * d) / 2) * np.log(2*np.pi*cl_var) -\n",
    "             ((n[i] - 1) * d/ 2) for i in range(m)]) - const_term\n",
    "\n",
    "    return(BIC)\n",
    "\n",
    "def plot_metric_vs_comp(df, problem_name, multiple_runs,\n",
    "                        title, ylabel):\n",
    "\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"N Components\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = plt.gca()\n",
    "\n",
    "    x_points = df.index.values\n",
    "    y_points = df[1]\n",
    "    if multiple_runs:\n",
    "        y_points = np.mean(df.iloc[:, 1: -1], axis=1)\n",
    "        y_std = np.std(df.iloc[:, 1: -1], axis=1)\n",
    "        plt.plot(x_points, y_points, 'o-', linewidth=1, markersize=2,\n",
    "                 label=ylabel)\n",
    "        plt.fill_between(x_points, y_points - y_std,\n",
    "                         y_points + y_std, alpha=0.2)\n",
    "    else:\n",
    "        plt.plot(x_points, y_points, 'o-', linewidth=1, markersize=2,\n",
    "                 label=ylabel)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "def run_plot_metric_vs_comp(out, dataset, metric, problem, title):\n",
    "    file = out + '{}_{}.csv'.format(dataset, metric)\n",
    "    df = pd.read_csv(file, header=None).dropna().set_index(0)\n",
    "    multiple_runs = True if problem == 'RP' else False\n",
    "    p = plot_metric_vs_comp(df=df, problem_name=problem, multiple_runs=multiple_runs,\n",
    "                            title=title, ylabel=metric)\n",
    "\n",
    "    p.savefig('{}/{}_{}.png'.format(out, dataset, metric),\n",
    "                                    format='png', bbox_inches='tight', dpi=150)\n",
    "\n",
    "def plot_complexity_curve(title, param, problem, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    grid_search = pd.read_csv('./{}/{}_cv_results.csv'.format(problem, dataset))\n",
    "    best_columns = ['mean_train_score', 'mean_test_score', 'mean_fit_time', 'mean_score_time', 'params']\n",
    "    best = pd.DataFrame(grid_search[best_columns].loc[grid_search.mean_test_score.idxmax()]).T.reset_index()\n",
    "    best.to_csv('./{}/{}_best.csv'.format(problem, dataset))\n",
    "    best_params = ast.literal_eval(best.loc[0, 'params'])\n",
    "\n",
    "    best_params.pop('{}__{}'.format(classifier, param))\n",
    "    for _param, value in best_params.items():\n",
    "        if isinstance(value, tuple):\n",
    "            grid_search['param_'+_param] = grid_search['param_'+_param].apply(ast.literal_eval)\n",
    "        grid_search = grid_search.loc[grid_search['param_'+_param] == value]\n",
    "\n",
    "    df = grid_search[['param_{}__{}'.format(classifier, param), \n",
    "                      'mean_test_score', \n",
    "                      'std_test_score', \n",
    "                      'mean_train_score', \n",
    "                      'std_train_score']].sort_values(by='param_{}__{}'.format(classifier, param))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores_mean = df['mean_train_score']\n",
    "    train_scores_std = df['std_train_score']\n",
    "    test_scores_mean = df['mean_test_score']\n",
    "    test_scores_std = df['std_test_score']\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(param_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2)\n",
    "    plt.fill_between(param_values, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2)\n",
    "    plt.plot(param_values, train_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_complexity_curve(clf_name, dataset, param, problem):    \n",
    "    print('Making complexity curve for', dataset)\n",
    "    plt = plot_complexity_curve('Complexity Curve: {} - {} - {}'.format(clf_name, dataset, param),\n",
    "                                param,\n",
    "                                problem,\n",
    "                                clf_name,\n",
    "                                dataset,\n",
    "                                ylim=None)\n",
    "\n",
    "    plt.savefig('./{}/{}_CC_{}.png'.format(problem, dataset, param), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8124, 23)\n",
      "Mushroom types:  Index(['e', 'p'], dtype='object')\n",
      "Labels balance: \n",
      " e    0.517971\n",
      "p    0.482029\n",
      "Name: type_label, dtype: float64\n",
      "Missing values for stalk root: 2480\n"
     ]
    }
   ],
   "source": [
    "# Data load and preprocessing\n",
    "\n",
    "# Mushroom dataset\n",
    "mushroom = pd.read_csv('mushroom.txt', header=None)\n",
    "print('Dataset shape: ' + str(mushroom.shape))\n",
    "mushroom.columns = ['type', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color','population', 'habitat']\n",
    "mushroom['type_label'] = mushroom['type'].astype('category')\n",
    "print('Mushroom types: ', str(mushroom['type_label'].cat.categories))\n",
    "print('Labels balance: \\n', mushroom['type_label'].value_counts()/mushroom['type_label'].size)\n",
    "# Code 1 is for poisonous mushrooms\n",
    "\n",
    "mushroom['type'] = mushroom['type_label'].cat.codes\n",
    "\n",
    "# There are no null values, missing is represented as ? only for stalk root\n",
    "print('Missing values for stalk root: '+ str(sum(mushroom['stalk-root']=='?')))\n",
    "\n",
    "# We remove feature stalk-root due to high number of missing values\n",
    "mushroom = pd.get_dummies(mushroom.drop(columns=['type_label','stalk-root']))\n",
    "mushroom = mushroom.astype(float)\n",
    "mushroom.type = mushroom.type.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (4898, 12)\n",
      "Quality values:  Index(['bad', 'good'], dtype='object')\n",
      "Labels balance: \n",
      " bad     0.783585\n",
      "good    0.216415\n",
      "Name: quality_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Wine dataset\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';')\n",
    "print('Dataset shape: ', str(wine.shape))\n",
    "\n",
    "# There are no null values in the dataset\n",
    "\n",
    "# Creation of class for good vs bad wines (good when greater or equal than 7)\n",
    "wine['quality_label'] = 'bad'\n",
    "wine.loc[wine['quality']>=7, 'quality_label'] = 'good'\n",
    "wine['quality_label'] = wine['quality_label'].astype('category')\n",
    "\n",
    "print('Quality values: ', str(wine['quality_label'].cat.categories))\n",
    "print('Labels balance: \\n', wine['quality_label'].value_counts()/wine['quality_label'].size)\n",
    "\n",
    "wine['quality_int'] = wine['quality']\n",
    "wine['quality'] = wine['quality_label'].cat.codes\n",
    "\n",
    "wine = wine.drop(['quality_label', 'quality_int'], axis=1)\n",
    "wine = wine.astype(float)\n",
    "wine.quality = wine.quality.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data       \n",
    "mushroomX = mushroom.drop('type', axis=1).values\n",
    "mushroomY = mushroom['type'].values\n",
    "\n",
    "wineX = wine.drop('quality', axis=1).values\n",
    "wineY = wine['quality'].values\n",
    "\n",
    "mushroomX = StandardScaler().fit_transform(mushroomX)\n",
    "wineX = StandardScaler().fit_transform(wineX)\n",
    "\n",
    "mushroom_trgX, mushroom_tstX, mushroom_trgY, mushroom_tstY = train_test_split(mushroomX, \n",
    "                                                                              mushroomY, \n",
    "                                                                              test_size=0.3, \n",
    "                                                                              random_state=0, \n",
    "                                                                              stratify=mushroomY) \n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = train_test_split(wineX, \n",
    "                                                              wineY, \n",
    "                                                              test_size=0.3, \n",
    "                                                              random_state=0, \n",
    "                                                              stratify=wineY)\n",
    "\n",
    "clusters =  [2, 5, 10, 15, 20, 25, 30, 35]\n",
    "dims_mushroom = [2, 5, 10, 15, 20, 30, 40, 50]\n",
    "dims_wine = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "d = wineX.shape[1]\n",
    "hiddens_wine = hiddens_wine = [(h,)*l for l in [1, 2] for h in [d//4, d//2, d, d*2]]\n",
    "alphas = [10**-x for x in np.arange(-1,5.01,1/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-273dffdffb07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'wine_cv_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "out = './PCA/'\n",
    "cmap = cm.get_cmap('Spectral') \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% data for 1\n",
    "\n",
    "pca = PCA(random_state=5)\n",
    "pca.fit(mushroomX)\n",
    "tmp = pd.Series(data=pca.explained_variance_) # , index = range(1, 501))\n",
    "tmp.to_csv(out + 'mushroom_ev.csv')\n",
    "\n",
    "pca = PCA(random_state=5)\n",
    "pca.fit(wineX)\n",
    "tmp = pd.Series(data=pca.explained_variance_) # , index = range(1, 65))\n",
    "tmp.to_csv(out + 'wine_ev.csv')\n",
    "\n",
    "metric = 'ev'\n",
    "problem = 'PCA'\n",
    "\n",
    "dataset = 'mushroom'\n",
    "title = 'Explained variance vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "dataset = 'wine'\n",
    "title = 'Explained variance vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "#%% Data for 2\n",
    "grid = {'pca__n_components': dims_wine, 'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}\n",
    "pca = PCA(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('pca', pca), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out + 'wine_cv_results.csv')\n",
    "\n",
    "make_complexity_curve('pca', 'wine', 'n_components', 'PCA')\n",
    "raise\n",
    "\n",
    "\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 60\n",
    "pca = PCA(n_components=dim, random_state=10)\n",
    "wineX2 = pca.fit_transform(wineX)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out + 'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/fastica_.py:118: UserWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn('FastICA did not converge. Consider increasing '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9ec022b7d09c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'wine_cv_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m#%% data for 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# ICA\n",
    "out = './ICA/'\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "#raise\n",
    "#%% data for 1\n",
    "\n",
    "ica = FastICA(random_state=5)\n",
    "kurt = {}\n",
    "for dim in dims_mushroom:\n",
    "    ica.set_params(n_components=dim)\n",
    "    tmp = ica.fit_transform(mushroomX)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp = tmp.kurt(axis=0)\n",
    "    kurt[dim] = tmp.abs().mean()\n",
    "\n",
    "kurt = pd.Series(kurt) \n",
    "kurt.to_csv(out + 'mushroom_kurt.csv')\n",
    "\n",
    "ica = FastICA(random_state=5)\n",
    "kurt = {}\n",
    "for dim in dims_wine:\n",
    "    ica.set_params(n_components=dim)\n",
    "    tmp = ica.fit_transform(wineX)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp = tmp.kurt(axis=0)\n",
    "    kurt[dim] = tmp.abs().mean()\n",
    "\n",
    "kurt = pd.Series(kurt) \n",
    "kurt.to_csv(out + 'wine_kurt.csv')\n",
    "\n",
    "metric = 'kurt'\n",
    "problem = 'ICA'\n",
    "\n",
    "dataset = 'mushroom'\n",
    "title = 'Kurtosis vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "dataset = 'wine'\n",
    "title = 'Kurtosis vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "#%% Data for 2\n",
    "grid = {'ica__n_components': dims_wine, 'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}\n",
    "ica = FastICA(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('ica', ica), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out + 'wine_cv_results.csv')\n",
    "make_complexity_curve('ica', 'wine', 'n_components', 'ICA')\n",
    "raise\n",
    "\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 60\n",
    "ica = FastICA(n_components=dim, random_state=10)\n",
    "wineX2 = ica.fit_transform(wineX)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out + 'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-770ee77d140b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'wine_cv_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#%% data for 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "out = './RF/'\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% data for 1\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, \n",
    "                             class_weight='balanced', \n",
    "                             random_state=5, \n",
    "                             n_jobs=-1)\n",
    "fs_mushroom = rfc.fit(mushroomX, mushroomY).feature_importances_ \n",
    "fs_wine = rfc.fit(wineX, wineY).feature_importances_ \n",
    "\n",
    "tmp = pd.Series(np.sort(fs_mushroom)[::-1])\n",
    "tmp.to_csv(out + 'mushroom_fi.csv')\n",
    "\n",
    "tmp = pd.Series(np.sort(fs_wine)[::-1])\n",
    "tmp.to_csv(out + 'wine_fi.csv')\n",
    "\n",
    "metric = 'fi'\n",
    "problem = 'RF'\n",
    "\n",
    "dataset = 'mushroom'\n",
    "title = 'Feature importance vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "dataset = 'wine'\n",
    "title = 'Feature importance vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "#%% Data for 2\n",
    "filtr = ImportanceSelect(rfc)\n",
    "grid = {'filter__n': dims_wine, 'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}  \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('filter', filtr), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out + 'wine_cv_results.csv')\n",
    "make_complexity_curve('filter', 'wine', 'n', 'RF')\n",
    "raise\n",
    "\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 40\n",
    "filtr = ImportanceSelect(rfc, dim)\n",
    "wineX2 = filtr.fit_transform(wineX, wineY)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out +'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-faea4339da03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'wine_cv_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#%% data for 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# Random Projection\n",
    "\n",
    "out = './RP/'\n",
    "cmap = cm.get_cmap('Spectral') \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#raise\n",
    "#%% data for 1\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i, dim in product(range(8), dims_mushroom):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    tmp[dim][i] = pairwiseDistCorr(rp.fit_transform(mushroomX), mushroomX)\n",
    "tmp = pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out + 'mushroom_cor.csv')\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i, dim in product(range(8), dims_wine):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    tmp[dim][i] = pairwiseDistCorr(rp.fit_transform(wineX), wineX)\n",
    "tmp = pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out + 'wine_cor.csv')\n",
    "\n",
    "metric = 'cor'\n",
    "title = 'Correlation vs Number of components'\n",
    "problem = 'RP'\n",
    "\n",
    "dataset = 'mushroom'\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "dataset = 'wine'\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i, dim in product(range(8), dims_mushroom):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    rp.fit(mushroomX)    \n",
    "    tmp[dim][i] = reconstructionError(rp, mushroomX)\n",
    "tmp = pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out + 'mushroom_rec_error.csv')\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i, dim in product(range(8), dims_wine):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    rp.fit(wineX)  \n",
    "    tmp[dim][i] = reconstructionError(rp, wineX)\n",
    "tmp =pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out + 'wine_rec_error.csv')\n",
    "\n",
    "metric = 'rec_error'\n",
    "problem = 'RP'\n",
    "\n",
    "dataset = 'mushroom'\n",
    "title = 'Reconstruction error vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "dataset = 'wine'\n",
    "title = 'Reconstruction error vs Number of components - {} - {}'.format(problem, dataset)\n",
    "run_plot_metric_vs_comp(out, dataset, metric, problem, title)\n",
    "\n",
    "#%% Data for 2\n",
    "grid = {'rp__n_components': dims_wine, 'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}\n",
    "rp = SparseRandomProjection(random_state=5)           \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('rp', rp), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out + 'wine_cv_results.csv')\n",
    "\n",
    "make_complexity_curve('rp', 'wine', 'n_components', 'RP')\n",
    "raise\n",
    "\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 60\n",
    "rp = SparseRandomProjection(n_components=dim, random_state=5)\n",
    "wineX2 = rp.fit_transform(wineX)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out + 'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8a5d64620207>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'wine_cv_results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "# Benchmark\n",
    "\n",
    "out = './BASE/'\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% benchmarking for chart type 2\n",
    "\n",
    "grid = {'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out + 'wine_cv_results.csv')\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2.040509999999813\n",
      "5 5.629069999999956\n",
      "10 13.23928799999976\n",
      "15 22.536873999999443\n",
      "20 35.670429999999214\n",
      "25 55.44510300000002\n",
      "30 75.12658199999987\n",
      "35 99.03682200000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:53: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:54: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:55: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:56: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2.2995000000009895\n",
      "5 6.039060999999492\n",
      "10 13.613205999998172\n",
      "15 23.46480900000097\n",
      "20 35.71979400000055\n",
      "25 54.01454499999818\n",
      "30 73.12796199999866\n",
      "35 95.61445900000035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:53: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:54: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:55: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:56: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n"
     ]
    }
   ],
   "source": [
    "# Clustering\n",
    "# python clustering.py PCA\n",
    "# python clustering.py BASE\n",
    "# python clustering.py ICA\n",
    "# python clustering.py RP\n",
    "# python clustering.py RF\n",
    "\n",
    "for dim_red in ['PCA', 'BASE', 'ICA', 'RP', 'RF']:\n",
    "    out = './{}/'.format(dim_red)\n",
    "\n",
    "    np.random.seed(0)\n",
    "\n",
    "    #%% Data for 1-3\n",
    "    SSE = defaultdict(dict)\n",
    "    ll = defaultdict(dict)\n",
    "    acc = defaultdict(lambda: defaultdict(dict))\n",
    "    adjMI = defaultdict(lambda: defaultdict(dict))\n",
    "    km = kmeans(random_state=5)\n",
    "    gmm = GMM(random_state=5)\n",
    "\n",
    "    st = clock()\n",
    "    for k in clusters:\n",
    "        km.set_params(n_clusters=k)\n",
    "        gmm.set_params(n_components=k)\n",
    "        km.fit(mushroomX)\n",
    "        gmm.fit(mushroomX)\n",
    "        SSE[k]['mushroom'] = km.score(mushroomX)\n",
    "        ll[k]['mushroom'] = gmm.score(mushroomX)    \n",
    "        acc[k]['mushroom']['Kmeans'] = cluster_acc(mushroomY, km.predict(mushroomX))\n",
    "        acc[k]['mushroom']['GMM'] = cluster_acc(mushroomY, gmm.predict(mushroomX))\n",
    "        adjMI[k]['mushroom']['Kmeans'] = ami(mushroomY, km.predict(mushroomX))\n",
    "        adjMI[k]['mushroom']['GMM'] = ami(mushroomY, gmm.predict(mushroomX))\n",
    "\n",
    "        km.fit(wineX)\n",
    "        gmm.fit(wineX)\n",
    "        SSE[k]['wine'] = km.score(wineX)\n",
    "        ll[k]['wine'] = gmm.score(wineX)\n",
    "        acc[k]['wine']['Kmeans'] = cluster_acc(wineY, km.predict(wineX))\n",
    "        acc[k]['wine']['GMM'] = cluster_acc(wineY, gmm.predict(wineX))\n",
    "        adjMI[k]['wine']['Kmeans'] = ami(wineY, km.predict(wineX))\n",
    "        adjMI[k]['wine']['GMM'] = ami(wineY, gmm.predict(wineX))\n",
    "        print(k, clock()-st)\n",
    "\n",
    "    SSE = (-pd.DataFrame(SSE)).T\n",
    "    SSE.rename(columns=lambda x: x + ' SSE (left)', inplace=True)\n",
    "    ll = pd.DataFrame(ll).T\n",
    "    ll.rename(columns=lambda x: x + ' log-likelihood', inplace=True)\n",
    "    acc = pd.Panel(acc)\n",
    "    adjMI = pd.Panel(adjMI)\n",
    "\n",
    "    SSE.to_csv(out + 'SSE.csv')\n",
    "    ll.to_csv(out + 'loglikelihood.csv')\n",
    "    acc.ix[:, :, 'mushroom'].to_csv(out + 'mushroom_acc.csv')\n",
    "    adjMI.ix[:, :, 'mushroom'].to_csv(out + ' mushroom_adjMI.csv')\n",
    "    acc.ix[:, :, 'wine'].to_csv(out + 'wine_acc.csv')\n",
    "    adjMI.ix[:, :, 'wine'].to_csv(out + ' wine_adjMI.csv')\n",
    "\n",
    "    #%% NN fit data (2,3)\n",
    "    grid = {'km__n_clusters': clusters, 'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}\n",
    "    mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "    km = kmeans(random_state=5)\n",
    "    pipe = Pipeline([('km', km), ('NN', mlp)])\n",
    "    gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "    gs.fit(wineX, wineY)\n",
    "    tmp = pd.DataFrame(gs.cv_results_)\n",
    "    tmp.to_csv(out + 'wine_kmeans_cv_results.csv')\n",
    "\n",
    "    grid = {'gmm__n_components': clusters, 'NN__alpha': alphas, 'NN__hidden_layer_sizes': hiddens_wine}\n",
    "    mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "    gmm = myGMM(random_state=5)\n",
    "    pipe = Pipeline([('gmm', gmm), ('NN', mlp)])\n",
    "    gs = GridSearchCV(pipe, grid, verbose=0, cv=5)\n",
    "\n",
    "    gs.fit(wineX, wineY)\n",
    "    tmp = pd.DataFrame(gs.cv_results_)\n",
    "    tmp.to_csv(out + 'wine_gmm_cv_results.csv')\n",
    "\n",
    "    # %% For chart 4/5\n",
    "    mushroomX2D = TSNE(verbose=0, random_state=5).fit_transform(mushroomX)\n",
    "    wineX2D = TSNE(verbose=0, random_state=5).fit_transform(wineX)\n",
    "\n",
    "    mushroom2D = pd.DataFrame(np.hstack((mushroomX2D, np.atleast_2d(mushroomY).T)), columns=['x','y','target'])\n",
    "    wine2D = pd.DataFrame(np.hstack((wineX2D, np.atleast_2d(wineY).T)), columns=['x','y','target'])\n",
    "\n",
    "    mushroom2D.to_csv(out + 'mushroom2D.csv')\n",
    "    wine2D.to_csv(out + 'wine2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# madelon tricks\n",
    "out = './PCA/'\n",
    "cmap = cm.get_cmap('Spectral') \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "mushroom = pd.read_hdf('./BASE/datasets.hdf','mushroom')        \n",
    "mushroomX = mushroom.drop('Class',1).copy().values\n",
    "mushroomY = mushroom['Class'].copy().values\n",
    "scaler =StandardScaler()\n",
    "\n",
    "mushroom_test = pd.read_hdf('./BASE/datasets.hdf','mushroom')        \n",
    "mushroom_tstX = mushroom_test.drop('Class',1).copy().values\n",
    "mushroom_tstY = mushroom_test['Class'].copy().values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mushroomX = scaler.fit_transform(mushroomX)\n",
    "mushroom_tstX = scaler.transform(mushroom_tstX)\n",
    "\n",
    "\n",
    "#Reproduce best estimator so far\n",
    "#if __name__=='__main__':\n",
    "#    rfc = RandomForestClassifier(n_estimators=100,class_weight='balanced',random_state=5,n_jobs=7)\n",
    "#    filtr = ImportanceSelect(rfc)\n",
    "#    grid ={'filter__n':[20],'NN__alpha':nn_reg,'NN__hidden_layer_sizes':nn_arch}\n",
    "#    mlp = MLPClassifier(activation='relu',max_iter=2000,early_stopping=True,random_state=5)\n",
    "#    pipe = Pipeline([('filter',filtr),('NN',mlp)])\n",
    "#    gs = GridSearchCV(pipe,grid,verbose=10,cv=5)    \n",
    "#    gs.fit(mushroomX,mushroomY)\n",
    "#    print('Best CV Score {}'.format(gs.best_score_))\n",
    "#    print('Test Score {}'.format(gs.score(mushroom_tstX,mushroom_tstY)))\n",
    "#    rf_features = gs.best_estimator_.steps[0][1].model.feature_importances_.argsort()[::-1][:20]\n",
    "    \n",
    "    \n",
    "# Use PCA to find true correct featuers\n",
    "pca = PCA(random_state=5, n_components=500)\n",
    "pca.fit(mushroomX)\n",
    "ve = pd.Series(pca.explained_variance_)\n",
    "ve.plot()\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "tmp = pd.DataFrame(pca.components_)\n",
    "tmp=tmp.iloc[-15:,:]\n",
    "pca_features=tmp.columns[tmp.abs().max()>0.1]\n",
    "\n",
    "    \n",
    "xx= mushroomX[:, pca_features]\n",
    "xx_tst = mushroom_tstX[:, pca_features]\n",
    "\n",
    "## NN testing - standard param set\n",
    "#grid ={'alpha':nn_reg,'hidden_layer_sizes':nn_arch}\n",
    "#mlp = MLPClassifier(activation='relu',max_iter=3000,early_stopping=False,random_state=5)\n",
    "#gs = GridSearchCV(mlp,param_grid=grid,verbose=10,cv=5)\n",
    "#gs.fit(mushroomX[:,pca_features],mushroomY)\n",
    "#print('NN - Standard params - Best CV Score {}'.format(gs.best_score_))\n",
    "#print('NN - Standard params - Test Score {}'.format(gs.score(xx_tst,mushroom_tstY)))\n",
    "#\n",
    "#\n",
    "#\n",
    "## NN testing - standard param set\n",
    "#grid ={'alpha':[1e-4,1e-5,1e-6],'hidden_layer_sizes':[(200,100,100,64,100,100,200)]}\n",
    "#mlp = MLPClassifier(activation='relu',max_iter=3000,early_stopping=False,random_state=5)\n",
    "#gs = GridSearchCV(mlp,param_grid=grid,verbose=10,cv=5)\n",
    "#gs.fit(mushroomX[:,pca_features],mushroomY)\n",
    "#print('NN - Big network- Best CV Score {}'.format(gs.best_score_))\n",
    "#print('NN - Big network - Test Score {}'.format(gs.score(xx_tst,mushroom_tstY)))\n",
    "\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier()\n",
    "grid = {'n_neighbors':range(1, 25, 1),'p':[1, 2], 'weights': ['uniform', 'distance']}\n",
    "gs = GridSearchCV(knn, param_grid=grid, cv=5, verbose=0)\n",
    "gs.fit(xx,mushroomY)\n",
    "print('KNN - Best CV Score {}'.format(gs.best_score_))\n",
    "print('KNN - Test Score {}'.format(gs.score(xx_tst, mushroom_tstY)))\n",
    "\n",
    "\n",
    "# SVM\n",
    "dis = pairwise_distances(xx)\n",
    "m = np.median(dis)\n",
    "gammas = [(1/m)*x for x in np.arange(0.1,2.1,0.1)]+[0.1,0.2,0.3,0.4,0.5]\n",
    "gammas = np.arange(0.1,0.9,0.05)\n",
    "\n",
    "gammas = [(1/m)*x for x in np.arange(0.1,2.1,0.1)]\n",
    "param_grid={'gamma':gammas,'C':[10**x for x in [-1,0,1,2,3]]}\n",
    "gs = GridSearchCV(SVC(kernel='rbf', C=1), param_grid=param_grid, cv=5, verbose=10, n_jobs=1)\n",
    "gs.fit(xx, mushroomY)\n",
    "print('SVM - Best CV Score {}'.format(gs.best_score_))\n",
    "print('SVM - Test Score {}'.format(gs.score(xx_tst, mushroom_tstY)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
