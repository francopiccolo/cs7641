{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from itertools import product\n",
    "from time import clock\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import scipy.sparse as sps\n",
    "from scipy.linalg import pinv\n",
    "from scipy.spatial import distance \n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.cluster import KMeans as kmeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import adjusted_mutual_info_score as ami, accuracy_score as acc\n",
    "\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "# from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "nn_arch= [(50, 50), (50,), (25,), (25, 25), (100, 25, 100)]\n",
    "nn_reg = [10**-x for x in range(1, 5)]\n",
    "\n",
    "def cluster_acc(Y, clusterLabels):\n",
    "    assert (Y.shape == clusterLabels.shape)\n",
    "    pred = np.empty_like(Y)\n",
    "    for label in set(clusterLabels):\n",
    "        mask = clusterLabels == label\n",
    "        sub = Y[mask]\n",
    "        target = Counter(sub).most_common(1)[0][0]\n",
    "        pred[mask] = target\n",
    "#    assert max(pred) == max(Y)\n",
    "#    assert min(pred) == min(Y)    \n",
    "    return acc(Y, pred)\n",
    "\n",
    "\n",
    "class myGMM(GMM):\n",
    "    def transform(self, X):\n",
    "        return self.predict_proba(X)\n",
    "        \n",
    "        \n",
    "def pairwiseDistCorr(X1, X2):\n",
    "    assert X1.shape[0] == X2.shape[0]\n",
    "    \n",
    "    d1 = pairwise_distances(X1)\n",
    "    d2 = pairwise_distances(X2)\n",
    "    return np.corrcoef(d1.ravel(), d2.ravel())[0,1]\n",
    "\n",
    "    \n",
    "def aveMI(X, Y):    \n",
    "    MI = MIC(X, Y) \n",
    "    return np.nanmean(MI)\n",
    "    \n",
    "  \n",
    "def reconstructionError(projections, X):\n",
    "    W = projections.components_\n",
    "    if sps.issparse(W):\n",
    "        W = W.todense()\n",
    "    p = pinv(W)\n",
    "    reconstructed = ((p@W)@(X.T)).T # Unproject projected data\n",
    "    errors = np.square(X-reconstructed)\n",
    "    return np.nanmean(errors)\n",
    "    \n",
    "    \n",
    "        \n",
    "# http://datascience.stackexchange.com/questions/6683/feature-selection-using-feature-importances-in-random-forests-with-scikit-learn          \n",
    "class ImportanceSelect(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, n=1):\n",
    "         self.model = model\n",
    "         self.n = n\n",
    "    def fit(self, *args, **kwargs):\n",
    "         self.model.fit(*args, **kwargs)\n",
    "         return self\n",
    "    def transform(self, X):\n",
    "         return X[:,self.model.feature_importances_.argsort()[::-1][:self.n]]\n",
    "                  \n",
    "#http://stats.stackexchange.com/questions/90769/using-bic-to-estimate-the-number-of-k-in-kmeans    \n",
    "def compute_bic(kmeans, X):\n",
    "    \"\"\"\n",
    "    Computes the BIC metric for a given clusters\n",
    "    Parameters:\n",
    "    -----------------------------------------\n",
    "    kmeans:  List of clustering object from scikit learn\n",
    "    X     :  multidimension np array of data points\n",
    "    Returns:\n",
    "    -----------------------------------------\n",
    "    BIC value\n",
    "    \"\"\"\n",
    "    # assign centers and labels\n",
    "    centers = [kmeans.cluster_centers_]\n",
    "    labels  = kmeans.labels_\n",
    "    #number of clusters\n",
    "    m = kmeans.n_clusters\n",
    "    # size of the clusters\n",
    "    n = np.bincount(labels)\n",
    "    #size of data set\n",
    "    N, d = X.shape\n",
    "\n",
    "    #compute variance for all clusters beforehand\n",
    "    cl_var = (1.0 / (N - m) / d) * sum([sum(distance.cdist(X[np.where(labels == i)], [centers[0][i]], 'euclidean')**2) for i in range(m)])\n",
    "\n",
    "    const_term = 0.5 * m * np.log(N) * (d+1)\n",
    "\n",
    "    BIC = np.sum([n[i] * np.log(n[i]) -\n",
    "               n[i] * np.log(N) -\n",
    "             ((n[i] * d) / 2) * np.log(2*np.pi*cl_var) -\n",
    "             ((n[i] - 1) * d/ 2) for i in range(m)]) - const_term\n",
    "\n",
    "    return(BIC)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data load and preprocessing\n",
    "\n",
    "# Mushroom dataset\n",
    "mushroom = pd.read_csv('mushroom.txt', header=None)\n",
    "print('Dataset shape: ' + str(mushroom.shape))\n",
    "mushroom.columns = ['type', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color','population', 'habitat']\n",
    "mushroom['type_label'] = mushroom['type'].astype('category')\n",
    "print('Mushroom types: ', str(mushroom['type_label'].cat.categories))\n",
    "print('Labels balance: \\n', mushroom['type_label'].value_counts()/mushroom['type_label'].size)\n",
    "# Code 1 is for poisonous mushrooms\n",
    "\n",
    "mushroom['type'] = mushroom['type_label'].cat.codes\n",
    "\n",
    "# There are no null values, missing is represented as ? only for stalk root\n",
    "print('Missing values for stalk root: '+ str(sum(mushroom['stalk-root']=='?')))\n",
    "\n",
    "# We remove feature stalk-root due to high number of missing values\n",
    "mushroom = pd.get_dummies(mushroom.drop(columns=['type_label','stalk-root']))\n",
    "mushroom = mushroom.astype(float)\n",
    "mushroom.type = mushroom.type.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wine dataset\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';')\n",
    "print('Dataset shape: ', str(wine.shape))\n",
    "\n",
    "# There are no null values in the dataset\n",
    "\n",
    "# Creation of class for good vs bad wines (good when greater or equal than 7)\n",
    "wine['quality_label'] = 'bad'\n",
    "wine.loc[wine['quality']>=7, 'quality_label'] = 'good'\n",
    "wine['quality_label'] = wine['quality_label'].astype('category')\n",
    "\n",
    "print('Quality values: ', str(wine['quality_label'].cat.categories))\n",
    "print('Labels balance: \\n', wine['quality_label'].value_counts()/wine['quality_label'].size)\n",
    "\n",
    "wine['quality_int'] = wine['quality']\n",
    "wine['quality'] = wine['quality_label'].cat.codes\n",
    "\n",
    "wine = wine.drop(['quality_label', 'quality_int'], axis=1)\n",
    "wine = wine.astype(float)\n",
    "wine.quality = wine.quality.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data       \n",
    "mushroomX = mushroom.drop('type', axis=1).values\n",
    "mushroomY = mushroom['type'].values\n",
    "\n",
    "wineX = wine.drop('quality', axis=1).values\n",
    "wineY = wine['quality'].values\n",
    "\n",
    "mushroomX = StandardScaler().fit_transform(mushroomX)\n",
    "wineX = StandardScaler().fit_transform(wineX)\n",
    "\n",
    "mushroom_trgX, mushroom_tstX, mushroom_trgY, mushroom_tstY = ms.train_test_split(mushroomX, mushroomY, test_size=0.3, random_state=0, stratify=mushroomY)     \n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = ms.train_test_split(wineX, wineY, test_size=0.3, random_state=0, stratify=wineY)\n",
    "\n",
    "clusters =  [2, 5, 10, 15, 20, 25, 30, 35, 40]\n",
    "dims = [2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "out = './PCA/'\n",
    "cmap = cm.get_cmap('Spectral') \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% data for 1\n",
    "\n",
    "pca = PCA(random_state=5)\n",
    "pca.fit(mushroomX)\n",
    "tmp = pd.Series(data=pca.explained_variance_, index = range(1, 501))\n",
    "tmp.to_csv(out+'mushroom scree.csv')\n",
    "\n",
    "pca = PCA(random_state=5)\n",
    "pca.fit(wineX)\n",
    "tmp = pd.Series(data=pca.explained_variance_, index = range(1, 65))\n",
    "tmp.to_csv(out+'wine scree.csv')\n",
    "\n",
    "\n",
    "#%% Data for 2\n",
    "grid ={'pca__n_components': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "pca = PCA(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('pca', pca), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'mushroom dim red.csv')\n",
    "\n",
    "grid = {'pca__n_components': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "pca = PCA(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('pca', pca),('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine dim red.csv')\n",
    "raise\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 5\n",
    "pca = PCA(n_components=dim, random_state=10)\n",
    "\n",
    "mushroomX2 = pca.fit_transform(mushroomX)\n",
    "mushroom2 = pd.DataFrame(np.hstack((mushroomX2, np.atleast_2d(mushroomY).T)))\n",
    "cols = list(range(mushroom2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "mushroom2.columns = cols\n",
    "mushroom2.to_hdf(out+'datasets.hdf', 'mushroom', complib='blosc', complevel=9)\n",
    "\n",
    "dim = 60\n",
    "pca = PCA(n_components=dim, random_state=10)\n",
    "wineX2 = pca.fit_transform(wineX)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out+'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICA\n",
    "out = './ICA/'\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "#raise\n",
    "#%% data for 1\n",
    "\n",
    "ica = FastICA(random_state=5)\n",
    "kurt = {}\n",
    "for dim in dims:\n",
    "    ica.set_params(n_components=dim)\n",
    "    tmp = ica.fit_transform(mushroomX)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp = tmp.kurt(axis=0)\n",
    "    kurt[dim] = tmp.abs().mean()\n",
    "\n",
    "kurt = pd.Series(kurt) \n",
    "kurt.to_csv(out+'mushroom scree.csv')\n",
    "\n",
    "\n",
    "ica = FastICA(random_state=5)\n",
    "kurt = {}\n",
    "for dim in dims:\n",
    "    ica.set_params(n_components=dim)\n",
    "    tmp = ica.fit_transform(wineX)\n",
    "    tmp = pd.DataFrame(tmp)\n",
    "    tmp = tmp.kurt(axis=0)\n",
    "    kurt[dim] = tmp.abs().mean()\n",
    "\n",
    "kurt = pd.Series(kurt) \n",
    "kurt.to_csv(out+'wine scree.csv')\n",
    "raise\n",
    "\n",
    "#%% Data for 2\n",
    "\n",
    "grid = {'ica__n_components': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "ica = FastICA(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('ica', ica), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'Mushroom dim red.csv')\n",
    "\n",
    "\n",
    "grid = {'ica__n_components': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "ica = FastICA(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('ica', ica), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine dim red.csv')\n",
    "raise\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 45\n",
    "ica = FastICA(n_components=dim, random_state=10)\n",
    "\n",
    "mushroomX2 = ica.fit_transform(mushroomX)\n",
    "mushroom2 = pd.DataFrame(np.hstack((mushroomX2,np.atleast_2d(mushroomY).T)))\n",
    "cols = list(range(mushroom2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "mushroom2.columns = cols\n",
    "mushroom2.to_hdf(out+'datasets.hdf', 'mushroom', complib='blosc', complevel=9)\n",
    "\n",
    "dim = 60\n",
    "ica = FastICA(n_components=dim, random_state=10)\n",
    "wineX2 = ica.fit_transform(wineX)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out+'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "out = './RF/'\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% data for 1\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=5, n_jobs=7)\n",
    "fs_mushroom = rfc.fit(mushroomX, mushroomY).feature_importances_ \n",
    "fs_wine = rfc.fit(wineX, wineY).feature_importances_ \n",
    "\n",
    "tmp = pd.Series(np.sort(fs_mushroom)[::-1])\n",
    "tmp.to_csv(out+'mushroom scree.csv')\n",
    "\n",
    "tmp = pd.Series(np.sort(fs_wine)[::-1])\n",
    "tmp.to_csv(out+'wine scree.csv')\n",
    "\n",
    "#%% Data for 2\n",
    "filtr = ImportanceSelect(rfc)\n",
    "grid = {'filter__n': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('filter', filtr), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'mushroom dim red.csv')\n",
    "\n",
    "\n",
    "grid = {'filter__n': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}  \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('filter', filtr), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine dim red.csv')\n",
    "#    raise\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 20\n",
    "filtr = ImportanceSelect(rfc, dim)\n",
    "\n",
    "mushroomX2 = filtr.fit_transform(mushroomX, mushroomY)\n",
    "mushroom2 = pd.DataFrame(np.hstack((mushroomX2, np.atleast_2d(mushroomY).T)))\n",
    "cols = list(range(mushroom2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "mushroom2.columns = cols\n",
    "mushroom2.to_hdf(out+'datasets.hdf', 'mushroom', complib='blosc', complevel=9)\n",
    "\n",
    "dim = 40\n",
    "filtr = ImportanceSelect(rfc, dim)\n",
    "wineX2 = filtr.fit_transform(wineX, wineY)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out+'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Projection\n",
    "\n",
    "out = './RP/'\n",
    "cmap = cm.get_cmap('Spectral') \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#raise\n",
    "#%% data for 1\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i,dim in product(range(10), dims):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    tmp[dim][i] = pairwiseDistCorr(rp.fit_transform(mushroomX), mushroomX)\n",
    "tmp = pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out+'mushroom scree1.csv')\n",
    "\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i,dim in product(range(10),dims):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    tmp[dim][i] = pairwiseDistCorr(rp.fit_transform(wineX), wineX)\n",
    "tmp = pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out+'wine scree1.csv')\n",
    "\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i,dim in product(range(10),dims):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    rp.fit(mushroomX)    \n",
    "    tmp[dim][i] = reconstructionError(rp, mushroomX)\n",
    "tmp = pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out+'mushroom scree2.csv')\n",
    "\n",
    "\n",
    "tmp = defaultdict(dict)\n",
    "for i,dim in product(range(10),dims):\n",
    "    rp = SparseRandomProjection(random_state=i, n_components=dim)\n",
    "    rp.fit(wineX)  \n",
    "    tmp[dim][i] = reconstructionError(rp, wineX)\n",
    "tmp =pd.DataFrame(tmp).T\n",
    "tmp.to_csv(out+'wine scree2.csv')\n",
    "\n",
    "#%% Data for 2\n",
    "\n",
    "grid = {'rp__n_components': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "rp = SparseRandomProjection(random_state=5)       \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('rp', rp), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'mushroom dim red.csv')\n",
    "\n",
    "\n",
    "grid = {'rp__n_components': dims, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "rp = SparseRandomProjection(random_state=5)           \n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('rp', rp), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine dim red.csv')\n",
    "raise\n",
    "#%% data for 3\n",
    "# Set this from chart 2 and dump, use clustering script to finish up\n",
    "dim = 10\n",
    "rp = SparseRandomProjection(n_components=dim, random_state=5)\n",
    "\n",
    "mushroomX2 = rp.fit_transform(mushroomX)\n",
    "mushroom2 = pd.DataFrame(np.hstack((mushroomX2, np.atleast_2d(mushroomY).T)))\n",
    "cols = list(range(mushroom2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "mushroom2.columns = cols\n",
    "mushroom2.to_hdf(out+'datasets.hdf', 'mushroom', complib='blosc', complevel=9)\n",
    "\n",
    "dim = 60\n",
    "rp = SparseRandomProjection(n_components=dim, random_state=5)\n",
    "wineX2 = rp.fit_transform(wineX)\n",
    "wine2 = pd.DataFrame(np.hstack((wineX2, np.atleast_2d(wineY).T)))\n",
    "cols = list(range(wine2.shape[1]))\n",
    "cols[-1] = 'Class'\n",
    "wine2.columns = cols\n",
    "wine2.to_hdf(out+'datasets.hdf', 'wine', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark\n",
    "\n",
    "out = './BASE/'\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% benchmarking for chart type 2\n",
    "\n",
    "grid ={'NN__alpha':nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'mushroom NN bmk.csv')\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "pipe = Pipeline([('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine NN bmk.csv')\n",
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "# python clustering.py PCA\n",
    "# python clustering.py BASE\n",
    "# python clustering.py ICA\n",
    "# python clustering.py RP\n",
    "# python clustering.py RF\n",
    "\n",
    "out = './{}/'.format(sys.argv[1])\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "#%% Data for 1-3\n",
    "SSE = defaultdict(dict)\n",
    "ll = defaultdict(dict)\n",
    "acc = defaultdict(lambda: defaultdict(dict))\n",
    "adjMI = defaultdict(lambda: defaultdict(dict))\n",
    "km = kmeans(random_state=5)\n",
    "gmm = GMM(random_state=5)\n",
    "\n",
    "st = clock()\n",
    "for k in clusters:\n",
    "    km.set_params(n_clusters=k)\n",
    "    gmm.set_params(n_components=k)\n",
    "    km.fit(mushroomX)\n",
    "    gmm.fit(mushroomX)\n",
    "    SSE[k]['mushroom'] = km.score(mushroomX)\n",
    "    ll[k]['mushroom'] = gmm.score(mushroomX)    \n",
    "    acc[k]['mushroom']['Kmeans'] = cluster_acc(mushroomY, km.predict(mushroomX))\n",
    "    acc[k]['mushroom']['GMM'] = cluster_acc(mushroomY, gmm.predict(mushroomX))\n",
    "    adjMI[k]['mushroom']['Kmeans'] = ami(mushroomY, km.predict(mushroomX))\n",
    "    adjMI[k]['mushroom']['GMM'] = ami(mushroomY, gmm.predict(mushroomX))\n",
    "    \n",
    "    km.fit(wineX)\n",
    "    gmm.fit(wineX)\n",
    "    SSE[k]['wine'] = km.score(wineX)\n",
    "    ll[k]['wine'] = gmm.score(wineX)\n",
    "    acc[k]['wine']['Kmeans'] = cluster_acc(wineY, km.predict(wineX))\n",
    "    acc[k]['wine']['GMM'] = cluster_acc(wineY, gmm.predict(wineX))\n",
    "    adjMI[k]['wine']['Kmeans'] = ami(wineY, km.predict(wineX))\n",
    "    adjMI[k]['wine']['GMM'] = ami(wineY, gmm.predict(wineX))\n",
    "    print(k, clock()-st)\n",
    "    \n",
    "    \n",
    "SSE = (-pd.DataFrame(SSE)).T\n",
    "SSE.rename(columns=lambda x: x+' SSE (left)', inplace=True)\n",
    "ll = pd.DataFrame(ll).T\n",
    "ll.rename(columns=lambda x: x+' log-likelihood', inplace=True)\n",
    "acc = pd.Panel(acc)\n",
    "adjMI = pd.Panel(adjMI)\n",
    "\n",
    "SSE.to_csv(out+'SSE.csv')\n",
    "ll.to_csv(out+'logliklihood.csv')\n",
    "acc.ix[:,:,'wine'].to_csv(out+'wine acc.csv')\n",
    "acc.ix[:,:,'mushroom'].to_csv(out+'mushroom acc.csv')\n",
    "adjMI.ix[:,:,'wine'].to_csv(out+'wine adjMI.csv')\n",
    "adjMI.ix[:,:,'mushroom'].to_csv(out+'mushroom adjMI.csv')\n",
    "\n",
    "\n",
    "#%% NN fit data (2,3)\n",
    "\n",
    "grid = {'km__n_clusters': clusters, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "km = kmeans(random_state=5)\n",
    "pipe = Pipeline([('km', km), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'mushroom cluster Kmeans.csv')\n",
    "\n",
    "\n",
    "grid = {'gmm__n_components': clusters, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "gmm = myGMM(random_state=5)\n",
    "pipe = Pipeline([('gmm', gmm), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(mushroomX, mushroomY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'mushroom cluster GMM.csv')\n",
    "\n",
    "grid = {'km__n_clusters': clusters, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "km = kmeans(random_state=5)\n",
    "pipe = Pipeline([('km', km), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine cluster Kmeans.csv')\n",
    "\n",
    "grid = {'gmm__n_components': clusters, 'NN__alpha': nn_reg, 'NN__hidden_layer_sizes': nn_arch}\n",
    "mlp = MLPClassifier(activation='relu', max_iter=2000, early_stopping=True, random_state=5)\n",
    "gmm = myGMM(random_state=5)\n",
    "pipe = Pipeline([('gmm', gmm), ('NN', mlp)])\n",
    "gs = GridSearchCV(pipe, grid, verbose=10, cv=5)\n",
    "\n",
    "gs.fit(wineX, wineY)\n",
    "tmp = pd.DataFrame(gs.cv_results_)\n",
    "tmp.to_csv(out+'wine cluster GMM.csv')\n",
    "\n",
    "\n",
    "# %% For chart 4/5\n",
    "mushroomX2D = TSNE(verbose=10, random_state=5).fit_transform(mushroomX)\n",
    "wineX2D = TSNE(verbose=10, random_state=5).fit_transform(wineX)\n",
    "\n",
    "mushroom2D = pd.DataFrame(np.hstack((mushroomX2D, np.atleast_2d(mushroomY).T)), columns=['x','y','target'])\n",
    "wine2D = pd.DataFrame(np.hstack((wineX2D, np.atleast_2d(wineY).T)), columns=['x','y','target'])\n",
    "\n",
    "mushroom2D.to_csv(out+'mushroom2D.csv')\n",
    "wine2D.to_csv(out+'wine2D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# madelon tricks\n",
    "out = './PCA/'\n",
    "cmap = cm.get_cmap('Spectral') \n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "mushroom = pd.read_hdf('./BASE/datasets.hdf','mushroom')        \n",
    "mushroomX = mushroom.drop('Class',1).copy().values\n",
    "mushroomY = mushroom['Class'].copy().values\n",
    "scaler =StandardScaler()\n",
    "\n",
    "mushroom_test = pd.read_hdf('./BASE/datasets.hdf','mushroom')        \n",
    "mushroom_tstX = mushroom_test.drop('Class',1).copy().values\n",
    "mushroom_tstY = mushroom_test['Class'].copy().values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mushroomX = scaler.fit_transform(mushroomX)\n",
    "mushroom_tstX = scaler.transform(mushroom_tstX)\n",
    "\n",
    "\n",
    "#Reproduce best estimator so far\n",
    "#if __name__=='__main__':\n",
    "#    rfc = RandomForestClassifier(n_estimators=100,class_weight='balanced',random_state=5,n_jobs=7)\n",
    "#    filtr = ImportanceSelect(rfc)\n",
    "#    grid ={'filter__n':[20],'NN__alpha':nn_reg,'NN__hidden_layer_sizes':nn_arch}\n",
    "#    mlp = MLPClassifier(activation='relu',max_iter=2000,early_stopping=True,random_state=5)\n",
    "#    pipe = Pipeline([('filter',filtr),('NN',mlp)])\n",
    "#    gs = GridSearchCV(pipe,grid,verbose=10,cv=5)    \n",
    "#    gs.fit(mushroomX,mushroomY)\n",
    "#    print('Best CV Score {}'.format(gs.best_score_))\n",
    "#    print('Test Score {}'.format(gs.score(mushroom_tstX,mushroom_tstY)))\n",
    "#    rf_features = gs.best_estimator_.steps[0][1].model.feature_importances_.argsort()[::-1][:20]\n",
    "    \n",
    "    \n",
    "# Use PCA to find true correct featuers\n",
    "pca = PCA(random_state=5, n_components=500)\n",
    "pca.fit(mushroomX)\n",
    "ve = pd.Series(pca.explained_variance_)\n",
    "ve.plot()\n",
    "plt.xlabel('Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "tmp = pd.DataFrame(pca.components_)\n",
    "tmp=tmp.iloc[-15:,:]\n",
    "pca_features=tmp.columns[tmp.abs().max()>0.1]\n",
    "\n",
    "    \n",
    "xx= mushroomX[:, pca_features]\n",
    "xx_tst = mushroom_tstX[:, pca_features]\n",
    "\n",
    "## NN testing - standard param set\n",
    "#grid ={'alpha':nn_reg,'hidden_layer_sizes':nn_arch}\n",
    "#mlp = MLPClassifier(activation='relu',max_iter=3000,early_stopping=False,random_state=5)\n",
    "#gs = GridSearchCV(mlp,param_grid=grid,verbose=10,cv=5)\n",
    "#gs.fit(mushroomX[:,pca_features],mushroomY)\n",
    "#print('NN - Standard params - Best CV Score {}'.format(gs.best_score_))\n",
    "#print('NN - Standard params - Test Score {}'.format(gs.score(xx_tst,mushroom_tstY)))\n",
    "#\n",
    "#\n",
    "#\n",
    "## NN testing - standard param set\n",
    "#grid ={'alpha':[1e-4,1e-5,1e-6],'hidden_layer_sizes':[(200,100,100,64,100,100,200)]}\n",
    "#mlp = MLPClassifier(activation='relu',max_iter=3000,early_stopping=False,random_state=5)\n",
    "#gs = GridSearchCV(mlp,param_grid=grid,verbose=10,cv=5)\n",
    "#gs.fit(mushroomX[:,pca_features],mushroomY)\n",
    "#print('NN - Big network- Best CV Score {}'.format(gs.best_score_))\n",
    "#print('NN - Big network - Test Score {}'.format(gs.score(xx_tst,mushroom_tstY)))\n",
    "\n",
    "\n",
    "#KNN\n",
    "knn = KNeighborsClassifier()\n",
    "grid={'n_neighbors':range(1, 25, 1),'p':[1, 2], 'weights': ['uniform', 'distance']}\n",
    "gs = GridSearchCV(knn, param_grid=grid, cv=5, verbose=10)\n",
    "gs.fit(xx,mushroomY)\n",
    "print('KNN - Best CV Score {}'.format(gs.best_score_))\n",
    "print('KNN - Test Score {}'.format(gs.score(xx_tst, mushroom_tstY)))\n",
    "\n",
    "\n",
    "# SVM\n",
    "dis = pairwise_distances(xx)\n",
    "m = np.median(dis)\n",
    "gammas = [(1/m)*x for x in np.arange(0.1,2.1,0.1)]+[0.1,0.2,0.3,0.4,0.5]\n",
    "gammas = np.arange(0.1,0.9,0.05)\n",
    "\n",
    "gammas = [(1/m)*x for x in np.arange(0.1,2.1,0.1)]\n",
    "param_grid={'gamma':gammas,'C':[10**x for x in [-1,0,1,2,3]]}\n",
    "gs = GridSearchCV(SVC(kernel='rbf', C=1), param_grid=param_grid, cv=5, verbose=10, n_jobs=1)\n",
    "gs.fit(xx, mushroomY)\n",
    "print('SVM - Best CV Score {}'.format(gs.best_score_))\n",
    "print('SVM - Test Score {}'.format(gs.score(xx_tst, mushroom_tstY)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
