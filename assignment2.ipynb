{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def balanced_accuracy(truth, pred):\n",
    "    wts = compute_sample_weight('balanced', truth)\n",
    "    return accuracy_score(truth, pred, sample_weight=wts)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy)    \n",
    "\n",
    "# Plots learning curve\n",
    "def plot_learning_curve(title,\n",
    "                        train_sizes,\n",
    "                        train_scores, test_scores, ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=None):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Grid search + learning curve\n",
    "def basicResults(clfObj, trgX, trgY, tstX, tstY, params, clf_type=None, dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    print('Calculating basic results for', dataset)\n",
    "    \n",
    "    # Saves results of hyperparameters grid search\n",
    "    cv = GridSearchCV(clfObj, \n",
    "                     n_jobs=-1, \n",
    "                     param_grid=params,\n",
    "                     verbose=False,\n",
    "                     cv=5, \n",
    "                     scoring=scorer, \n",
    "                     return_train_score=True)\n",
    "    cv.fit(trgX, trgY)\n",
    "    st = time()\n",
    "    cv.best_estimator_.fit(trgX, trgY)\n",
    "    train_time = time() - st\n",
    "    st = time()\n",
    "    cv.predict(trgX[0].reshape(1, -1))\n",
    "    predict_time = time() - st\n",
    "    \n",
    "    def schedule_to_str(schedule):\n",
    "        schedule = str(schedule)\n",
    "        if 'Geom' in schedule:\n",
    "            return 'geom_decay'\n",
    "        elif 'Exp' in schedule:\n",
    "            return 'exp_decay'\n",
    "        elif 'Arith' in schedule:\n",
    "            return 'arith_decay'\n",
    "    \n",
    "    best_params = cv.best_params_.copy()\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    \n",
    "    if 'NN_sa__schedule' in params:\n",
    "        regTable['param_NN_sa__schedule'] = regTable['param_NN_sa__schedule'].apply(lambda x: schedule_to_str(x))\n",
    "        best_params['NN_sa__schedule'] = schedule_to_str(best_params['NN_sa__schedule'])\n",
    "    \n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type, dataset), index=False)\n",
    "    train_score = cv.score(trgX, trgY)\n",
    "    test_score = cv.score(tstX, tstY)\n",
    "\n",
    "    # Saves best iteration\n",
    "    results = pd.DataFrame({'classifier': [clf_type],\n",
    "                 'dataset': [dataset],\n",
    "                 'train_score': [train_score],\n",
    "                 'test_score': [test_score],\n",
    "                 'train_time': [train_time],\n",
    "                 'predict_time': [predict_time],\n",
    "                 'params': [best_params]})\n",
    "    \n",
    "    results.to_csv('./output/{}_{}_best.csv'.format(clf_type, dataset))\n",
    "    \n",
    "    # Saves learning curve\n",
    "    N = trgY.shape[0]\n",
    "    train_sizes = [50,100]+[int(N*x/10) for x in range(1,8)]\n",
    "    np.random.seed(55)\n",
    "    curve = learning_curve(cv.best_estimator_,\n",
    "                           trgX, trgY,\n",
    "                           cv=5,\n",
    "                           train_sizes=train_sizes,\n",
    "                           verbose=False,\n",
    "                           scoring=scorer)\n",
    "\n",
    "    curve_train_scores = pd.DataFrame(index=curve[0], data=curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index=curve[0], data=curve[2])\n",
    "    \n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type, dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type, dataset))\n",
    "    \n",
    "    plt = plot_learning_curve('Learning Curve: {} - {}'.format(clf_type, dataset),\n",
    "                        train_sizes,\n",
    "                        curve_train_scores, curve_test_scores, ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=None)\n",
    "    \n",
    "    plt.savefig('./output/images/{}_{}_LC.png'.format(clf_type, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return cv\n",
    "\n",
    "def iterationLC(clfObj, trgX, trgY, tstX, tstY, params, clf_type=None, dataset=None):\n",
    "    print('Calculating iteration learning curve for ',dataset)\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name: value})\n",
    "        clfObj.fit(trgX, trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY, pred))\n",
    "        clfObj.fit(trgX, trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY, pred))\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/{}_{}_ILC.csv'.format(clf_type, dataset), index=False)\n",
    "    return\n",
    "    \n",
    "# Timing curve\n",
    "def plot_timing_curve(title, data_sizes, fit_times, predict_times, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Testing Size (% of total)\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    predict_times_mean = np.mean(predict_times, axis=1)\n",
    "    predict_times_std = np.std(predict_times, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(data_sizes, fit_times_mean - fit_times_std,\n",
    "                     fit_times_mean + fit_times_std, alpha=0.2)\n",
    "    plt.fill_between(data_sizes, predict_times_mean - predict_times_std,\n",
    "                     predict_times_mean + predict_times_std, alpha=0.2)\n",
    "    plt.plot(data_sizes, predict_times_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Predict time\")\n",
    "    plt.plot(data_sizes, fit_times_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Fit time\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_timing_curve(X, Y, clf, clf_name, dataset):\n",
    "    out = defaultdict(dict)\n",
    "    print('Making timing curve for', dataset)\n",
    "    fracs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    for frac in fracs:  \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=frac, random_state=42)\n",
    "        st = time()\n",
    "        np.random.seed(55)\n",
    "        clf.fit(X_train, y_train)\n",
    "        out['train'][frac]= time() - st\n",
    "        st = time()\n",
    "        clf.predict(X_test)\n",
    "        out['test'][frac]= time() - st\n",
    "    out = pd.DataFrame(out)\n",
    "    out.to_csv('./output/{}_{}_timing.csv'.format(clf_name, dataset))\n",
    "    train_df = pd.DataFrame(out['train'], index=fracs)\n",
    "    test_df = pd.DataFrame(out['test'], fracs)\n",
    "    plt = plot_timing_curve('Timing Curve: {} - {}'.format(clf_name, dataset),\n",
    "                            np.array(fracs) * 100, \n",
    "                            train_df, test_df)\n",
    "    \n",
    "    plt.savefig('./output/images/{}_{}_TC.png'.format(clf_name, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_complexity_curve(title, param, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    best = pd.read_csv('./output/{}_{}_best.csv'.format(classifier, dataset))\n",
    "    best_params = ast.literal_eval(best.loc[0, 'params'])\n",
    "#     print(type(best_params['NN_ga__learning_rate']))\n",
    "    grid_search = pd.read_csv('./output/{}_{}_reg.csv'.format(classifier, dataset))\n",
    "#     print(grid_search['param_NN_ga__learning_rate'].dtype)\n",
    "#     print(grid_search['param_NN_ga__learning_rate'])\n",
    "    best_params.pop('{}__{}'.format(classifier, param))\n",
    "    for _param, value in best_params.items():\n",
    "        if isinstance(value, tuple):\n",
    "            grid_search['param_'+_param] = grid_search['param_'+_param].apply(ast.literal_eval)\n",
    "        grid_search = grid_search.loc[grid_search['param_'+_param] == value]\n",
    "#         print(_param, value, grid_search.iloc[0:2])\n",
    "\n",
    "    df = grid_search[['param_{}__{}'.format(classifier, param), \n",
    "                      'mean_test_score', \n",
    "                      'std_test_score', \n",
    "                      'mean_train_score', \n",
    "                      'std_train_score']].sort_values(by='param_{}__{}'.format(classifier, param))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores_mean = df['mean_train_score']\n",
    "    train_scores_std = df['std_train_score']\n",
    "    test_scores_mean = df['mean_test_score']\n",
    "    test_scores_std = df['std_test_score']\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(param_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2)\n",
    "    plt.fill_between(param_values, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2)\n",
    "    plt.plot(param_values, train_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_complexity_curve(clf_name, dataset, param):    \n",
    "    print('Making complexity curve for', dataset)\n",
    "    plt = plot_complexity_curve('Complexity Curve: {} - {} - {}'.format(clf_name, dataset, param),\n",
    "                                param,\n",
    "                                clf_name,\n",
    "                                dataset,\n",
    "                                ylim=None)\n",
    "\n",
    "    plt.savefig('./output/images/{}_{}_CC_{}.png'.format(clf_name, dataset, param), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_iteration_learning_curve(title, param, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    df = pd.read_csv('./output/{}_{}_ILC.csv'.format(classifier, dataset))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores = df['train acc']\n",
    "    test_scores = df['test acc']\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.plot(param_values, train_scores, \n",
    "             'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores, \n",
    "             'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_iteration_learning_curve(clf_name, dataset, param):    \n",
    "    print('Making iteration learning curve for', dataset)\n",
    "    plt = plot_iteration_learning_curve('Iteration Learning Curve: {} - {}'.format(clf_name, dataset),\n",
    "                                        param,\n",
    "                                        clf_name,\n",
    "                                        dataset,\n",
    "                                        ylim=None)\n",
    "\n",
    "    plt.savefig('./output/images/{}_{}_ILC.png'.format(clf_name, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (4898, 12)\n",
      "Quality values:  Index(['bad', 'good'], dtype='object')\n",
      "Labels balance: \n",
      " bad     0.783585\n",
      "good    0.216415\n",
      "Name: quality_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Wine dataset\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';')\n",
    "print('Dataset shape: ', str(wine.shape))\n",
    "\n",
    "# There are no null values in the dataset\n",
    "\n",
    "# Creation of class for good vs bad wines (good when greater or equal than 7)\n",
    "wine['quality_label'] = 'bad'\n",
    "wine.loc[wine['quality']>=7, 'quality_label'] = 'good'\n",
    "wine['quality_label'] = wine['quality_label'].astype('category')\n",
    "\n",
    "print('Quality values: ', str(wine['quality_label'].cat.categories))\n",
    "print('Labels balance: \\n', wine['quality_label'].value_counts()/wine['quality_label'].size)\n",
    "\n",
    "wine['quality_int'] = wine['quality']\n",
    "wine['quality'] = wine['quality_label'].cat.codes\n",
    "\n",
    "wine = wine.drop(['quality_label', 'quality_int'], axis=1)\n",
    "wine = wine.astype(float)\n",
    "wine.quality = wine.quality.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data       \n",
    "wineX = wine.drop('quality', axis=1).values\n",
    "wineY = wine['quality'].values\n",
    "\n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = train_test_split(wineX, wineY, test_size=0.3, random_state=0, stratify=wineY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "class NeuralNetworkF(mlrose.NeuralNetwork):\n",
    "    def get_params(self, deep):\n",
    "        return {'hidden_nodes': self.hidden_nodes,\n",
    "                'max_iters': self.max_iters,\n",
    "                'bias': self.bias,\n",
    "                'is_classifier': self.is_classifier,\n",
    "                'learning_rate': self.lr,\n",
    "                'early_stopping': self.early_stopping,\n",
    "                'clip_max': self.clip_max,\n",
    "                'schedule': self.schedule,\n",
    "                'pop_size': self.pop_size,\n",
    "                'mutation_prob': self.mutation_prob}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "nn_params = {'hidden_nodes': [22],\n",
    "             'activation': 'relu',\n",
    "             'bias': True,\n",
    "             'is_classifier': True,\n",
    "             'early_stopping': True,\n",
    "             'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for wine\n",
      "Making complexity curve for wine\n",
      "Making timing curve for wine\n",
      "Calculating iteration learning curve for  wine\n",
      "Making iteration learning curve for wine\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks random hill climb\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                  ('NN_rhc', NeuralNetworkF(algorithm='random_hill_climb',\n",
    "                                        **nn_params))])\n",
    "\n",
    "learning_rate = [10**x for x in np.arange(-4, 0, 1/2)]\n",
    "\n",
    "params_wine = {'NN_rhc__max_iters': [5000],\n",
    "               'NN_rhc__max_attempts': [50],\n",
    "               'NN_rhc__learning_rate': learning_rate}\n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'NN_rhc', 'wine')        \n",
    "\n",
    "make_complexity_curve('NN_rhc', 'wine', 'learning_rate')\n",
    "\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'NN_rhc', 'wine')\n",
    "\n",
    "max_iters = [2**x for x in range(14)]\n",
    "pipeW.set_params(**{'NN_rhc__early_stopping': False})    \n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'NN_rhc__max_iters': max_iters}, \n",
    "             'NN_rhc', 'wine')\n",
    "make_iteration_learning_curve('NN_rhc', 'wine', 'max_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for wine\n",
      "Making complexity curve for wine\n",
      "Making timing curve for wine\n",
      "Calculating iteration learning curve for  wine\n",
      "Making iteration learning curve for wine\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks simulated annealing\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                  ('NN_sa', NeuralNetworkF(algorithm='simulated_annealing',\n",
    "                                        **nn_params))])\n",
    "\n",
    "learning_rate = [10**x for x in np.arange(-4, 1/2, 1/2)]\n",
    "schedule = [mlrose.GeomDecay(), mlrose.ArithDecay(), mlrose.ExpDecay()]\n",
    "\n",
    "params_wine = {'NN_sa__max_iters': [5000],\n",
    "               'NN_sa__max_attempts': [50],\n",
    "               'NN_sa__learning_rate': learning_rate,\n",
    "               'NN_sa__schedule': schedule}\n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'NN_sa', 'wine')        \n",
    "\n",
    "make_complexity_curve('NN_sa', 'wine', 'learning_rate')\n",
    "\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'NN_sa', 'wine')\n",
    "\n",
    "max_iters = [2**x for x in range(14)]\n",
    "pipeW.set_params(**{'NN_sa__early_stopping': False})    \n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'NN_sa__max_iters': max_iters}, \n",
    "             'NN_sa', 'wine')\n",
    "make_iteration_learning_curve('NN_sa', 'wine', 'max_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for wine\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks Genetic Algorithm\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                  ('NN_ga', NeuralNetworkF(algorithm='genetic_alg',\n",
    "                                        **nn_params))])\n",
    "\n",
    "learning_rate = [round(10**x, 8) for x in np.arange(-4, 0, 1/2)]\n",
    "mutation_prob = [round(10**x, 8) for x in np.arange(-4, 0, 1/2)]\n",
    "pop_size = [round(10**x) for x in np.arange(1, 3.5, 1/2)]\n",
    "\n",
    "params_wine = {'NN_ga__max_iters': [2000],\n",
    "               'NN_ga__max_attempts': [20],\n",
    "               'NN_ga__learning_rate': learning_rate,\n",
    "               'NN_ga__pop_size': pop_size,\n",
    "               'NN_ga__mutation_prob': mutation_prob}\n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'NN_ga', 'wine')        \n",
    "\n",
    "make_complexity_curve('NN_ga', 'wine', 'learning_rate')\n",
    "\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'NN_ga', 'wine')\n",
    "\n",
    "max_iters = [2**x for x in range(12)]\n",
    "pipeW.set_params(**{'NN_ga__early_stopping': False})\n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'NN_ga__max_iters': max_iters}, \n",
    "             'NN_ga', 'wine')\n",
    "make_iteration_learning_curve('NN_ga', 'wine', 'max_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making complexity curve for wine\n"
     ]
    }
   ],
   "source": [
    "make_complexity_curve('NN_ga', 'wine', 'pop_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization experiments\n",
    "lengths = [2**x for x in range(4, 10)]\n",
    "results = pd.DataFrame(columns=['algorithm', 'length', 'iterations', 'time', 'fitness'])\n",
    "max_iters = [2**x for x in range(13)]\n",
    "max_attempts = [ceil(i/100) for i in max_iters]\n",
    "algorithms = ['sa', 'rhc', 'mimic', 'ga']\n",
    "problems = ['OneMax', 'FlipFlop', 'FourPeaks']\n",
    "\n",
    "for length in lengths:\n",
    "    for iteration, attempt in zip(max_iters, max_attempts):\n",
    "        for algorithm in algorithms:\n",
    "            for problem_name in problems:\n",
    "                \n",
    "                if problem_name == 'OneMax':                    \n",
    "                    fitness = mlrose.OneMax()\n",
    "                elif problem_name == 'FlipFlop': \n",
    "                    fitness = mlrose.FlipFlop()\n",
    "                elif problem_name == 'FourPeaks':\n",
    "                    fitness = mlrose.FourPeaks()\n",
    "                    \n",
    "                problem = mlrose.DiscreteOpt(length=length,\n",
    "                                             fitness_fn=fitness,\n",
    "                                             maximize=True, \n",
    "                                             max_val=2)\n",
    "                \n",
    "                init_state = np.random.randint(0, 2, length)\n",
    "                \n",
    "                ti = time()\n",
    "                if algorithm == 'sa':\n",
    "                    schedule = mlrose.ExpDecay()  \n",
    "                    _, fitness = mlrose.simulated_annealing(problem,\n",
    "                                                            schedule=schedule,\n",
    "                                                            max_attempts=attempt,\n",
    "                                                            max_iters=iteration,\n",
    "                                                            init_state=init_state)\n",
    "\n",
    "                elif algorithm == 'rhc':\n",
    "                    _, fitness = mlrose.random_hill_climb(problem, \n",
    "                                                          max_attempts=attempt, \n",
    "                                                          max_iters=iteration, \n",
    "                                                          restarts=0, \n",
    "                                                          init_state=init_state)\n",
    "\n",
    "                elif algorithm == 'ga':\n",
    "                    if iteration < 2000:\n",
    "                        _, fitness = mlrose.genetic_alg(problem, \n",
    "                                                        pop_size=200, \n",
    "                                                        mutation_prob=0.1, \n",
    "                                                        max_attempts=attempt, \n",
    "                                                        max_iters=iteration)\n",
    "                    else:\n",
    "                        fitness = 0\n",
    "                        \n",
    "                elif algorithm == 'mimic':\n",
    "                    if iteration < 50:\n",
    "                        _, fitness = mlrose.mimic(problem, \n",
    "                                                  pop_size=200, \n",
    "                                                  keep_pct=0.2, \n",
    "                                                  max_attempts=attempt, \n",
    "                                                  max_iters=iteration)\n",
    "                    else: \n",
    "                        fitness = 0\n",
    "                        \n",
    "                tf = time()\n",
    "                results = results.append(pd.Series({'problem': problem_name,\n",
    "                                                    'algorithm': algorithm,\n",
    "                                                    'length': length,\n",
    "                                                    'iterations': iteration,\n",
    "                                                    'time': tf-ti,\n",
    "                                                    'fitness': fitness}),\n",
    "                                         ignore_index=True)\n",
    "results.to_csv('./output/opt_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./output/opt_results.csv')\n",
    "df['log_time'] = np.log(df['time'])\n",
    "for length in df.length.unique():\n",
    "    for problem in df.problem.unique():\n",
    "        for graph_type in ['fitness', 'log_time']:\n",
    "            length_mask = df.length == length\n",
    "            problem_mask = df.problem == problem\n",
    "            mask = length_mask & problem_mask\n",
    "            df[mask][['algorithm', 'iterations', graph_type]].pivot(index='iterations', columns='algorithm', values=graph_type).plot()\n",
    "            plt.ylabel(graph_type)\n",
    "            plt.savefig('./output/images/{}_{}_{}.png'.format(problem, length, graph_type), format='png', dpi=150)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>length</th>\n",
       "      <th>iterations</th>\n",
       "      <th>time</th>\n",
       "      <th>fitness</th>\n",
       "      <th>problem</th>\n",
       "      <th>log_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>788</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>8.662154e+01</td>\n",
       "      <td>14.0</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>4.461548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>1.738836e+02</td>\n",
       "      <td>12.0</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>5.158386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>812</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>3.468919e+02</td>\n",
       "      <td>13.0</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>5.849013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>824</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>4.324171e+02</td>\n",
       "      <td>19.0</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>6.069391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>836</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>2.646129e+02</td>\n",
       "      <td>11.0</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>5.578268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>848</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>32</td>\n",
       "      <td>1.727977e+02</td>\n",
       "      <td>11.0</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>5.152122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>860</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>64</td>\n",
       "      <td>1.192093e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-13.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>872</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>128</td>\n",
       "      <td>2.145767e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-13.052013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>884</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>256</td>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-13.862944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>896</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>512</td>\n",
       "      <td>1.907349e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-13.169796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>908</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.192093e-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-13.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>920</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>7.152557e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-14.150626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>932</td>\n",
       "      <td>mimic</td>\n",
       "      <td>512</td>\n",
       "      <td>4096</td>\n",
       "      <td>9.536743e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FourPeaks</td>\n",
       "      <td>-13.862944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0 algorithm  length  iterations          time  fitness  \\\n",
       "788         788     mimic     512           1  8.662154e+01     14.0   \n",
       "800         800     mimic     512           2  1.738836e+02     12.0   \n",
       "812         812     mimic     512           4  3.468919e+02     13.0   \n",
       "824         824     mimic     512           8  4.324171e+02     19.0   \n",
       "836         836     mimic     512          16  2.646129e+02     11.0   \n",
       "848         848     mimic     512          32  1.727977e+02     11.0   \n",
       "860         860     mimic     512          64  1.192093e-06      NaN   \n",
       "872         872     mimic     512         128  2.145767e-06      NaN   \n",
       "884         884     mimic     512         256  9.536743e-07      NaN   \n",
       "896         896     mimic     512         512  1.907349e-06      NaN   \n",
       "908         908     mimic     512        1024  1.192093e-06      NaN   \n",
       "920         920     mimic     512        2048  7.152557e-07      NaN   \n",
       "932         932     mimic     512        4096  9.536743e-07      NaN   \n",
       "\n",
       "       problem   log_time  \n",
       "788  FourPeaks   4.461548  \n",
       "800  FourPeaks   5.158386  \n",
       "812  FourPeaks   5.849013  \n",
       "824  FourPeaks   6.069391  \n",
       "836  FourPeaks   5.578268  \n",
       "848  FourPeaks   5.152122  \n",
       "860  FourPeaks -13.639800  \n",
       "872  FourPeaks -13.052013  \n",
       "884  FourPeaks -13.862944  \n",
       "896  FourPeaks -13.169796  \n",
       "908  FourPeaks -13.639800  \n",
       "920  FourPeaks -14.150626  \n",
       "932  FourPeaks -13.862944  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results for a specific length problem algo\n",
    "length_mask = df.length == 512\n",
    "problem_mask = df.problem == 'FourPeaks'\n",
    "algorithm_mask = df.algorithm == 'mimic'\n",
    "mask = length_mask & problem_mask & algorithm_mask\n",
    "df[mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
