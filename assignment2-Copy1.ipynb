{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def balanced_accuracy(truth, pred):\n",
    "    wts = compute_sample_weight('balanced', truth)\n",
    "    return accuracy_score(truth, pred, sample_weight=wts)\n",
    "\n",
    "scorer = make_scorer(balanced_accuracy)    \n",
    "\n",
    "# Plots learning curve\n",
    "def plot_learning_curve(title,\n",
    "                        train_sizes,\n",
    "                        train_scores, test_scores, ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=None):\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Grid search + learning curve\n",
    "def basicResults(clfObj, trgX, trgY, tstX, tstY, params, clf_type=None, dataset=None):\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    print('Calculating basic results for', dataset)\n",
    "    \n",
    "    # Saves results of hyperparameters grid search\n",
    "    cv = GridSearchCV(clfObj, \n",
    "                     n_jobs=-1, \n",
    "                     param_grid=params,\n",
    "                     verbose=False,\n",
    "                     cv=5, \n",
    "                     scoring=scorer, \n",
    "                     return_train_score=True)\n",
    "    cv.fit(trgX, trgY)\n",
    "    st = time()\n",
    "    cv.best_estimator_.fit(trgX, trgY)\n",
    "    train_time = time() - st\n",
    "    st = time()\n",
    "    cv.predict(trgX[0].reshape(1, -1))\n",
    "    predict_time = time() - st\n",
    "    \n",
    "    def schedule_to_str(schedule):\n",
    "        schedule = str(schedule)\n",
    "        if 'Geom' in schedule:\n",
    "            return 'geom_decay'\n",
    "        elif 'Exp' in schedule:\n",
    "            return 'exp_decay'\n",
    "        elif 'Arith' in schedule:\n",
    "            return 'arith_decay'\n",
    "    \n",
    "    best_params = cv.best_params_.copy()\n",
    "    regTable = pd.DataFrame(cv.cv_results_)\n",
    "    \n",
    "    if 'NN_sa__schedule' in params:\n",
    "        regTable['param_NN_sa__schedule'] = regTable['param_NN_sa__schedule'].apply(lambda x: schedule_to_str(x))\n",
    "        best_params['NN_sa__schedule'] = schedule_to_str(best_params['NN_sa__schedule'])\n",
    "    \n",
    "    regTable.to_csv('./output/{}_{}_reg.csv'.format(clf_type, dataset), index=False)\n",
    "    train_score = cv.score(trgX, trgY)\n",
    "    test_score = cv.score(tstX, tstY)\n",
    "\n",
    "    # Saves best iteration\n",
    "    results = pd.DataFrame({'classifier': [clf_type],\n",
    "                 'dataset': [dataset],\n",
    "                 'train_score': [train_score],\n",
    "                 'test_score': [test_score],\n",
    "                 'train_time': [train_time],\n",
    "                 'predict_time': [predict_time],\n",
    "                 'params': [best_params]})\n",
    "    \n",
    "    results.to_csv('./output/{}_{}_best.csv'.format(clf_type, dataset))\n",
    "    \n",
    "    # Saves learning curve\n",
    "    N = trgY.shape[0]\n",
    "    train_sizes = [50,100]+[int(N*x/10) for x in range(1,8)]\n",
    "    np.random.seed(55)\n",
    "    curve = learning_curve(cv.best_estimator_,\n",
    "                           trgX, trgY,\n",
    "                           cv=5,\n",
    "                           train_sizes=train_sizes,\n",
    "                           verbose=False,\n",
    "                           scoring=scorer)\n",
    "\n",
    "    curve_train_scores = pd.DataFrame(index=curve[0], data=curve[1])\n",
    "    curve_test_scores  = pd.DataFrame(index=curve[0], data=curve[2])\n",
    "    \n",
    "    curve_train_scores.to_csv('./output/{}_{}_LC_train.csv'.format(clf_type, dataset))\n",
    "    curve_test_scores.to_csv('./output/{}_{}_LC_test.csv'.format(clf_type, dataset))\n",
    "    \n",
    "    plt = plot_learning_curve('Learning Curve: {} - {}'.format(clf_type, dataset),\n",
    "                        train_sizes,\n",
    "                        curve_train_scores, curve_test_scores, ylim=None, \n",
    "                        cv=None,\n",
    "                        n_jobs=None)\n",
    "    \n",
    "    plt.savefig('./output/images/{}_{}_LC.png'.format(clf_type, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return cv\n",
    "\n",
    "def iterationLC(clfObj, trgX, trgY, tstX, tstY, params, clf_type=None, dataset=None):\n",
    "    print('Calculating iteration learning curve for ',dataset)\n",
    "    np.random.seed(55)\n",
    "    if clf_type is None or dataset is None:\n",
    "        raise\n",
    "    \n",
    "    d = defaultdict(list)\n",
    "    name = list(params.keys())[0]\n",
    "    for value in list(params.values())[0]:        \n",
    "        d['param_{}'.format(name)].append(value)\n",
    "        clfObj.set_params(**{name: value})\n",
    "        clfObj.fit(trgX, trgY)\n",
    "        pred = clfObj.predict(trgX)\n",
    "        d['train acc'].append(balanced_accuracy(trgY, pred))\n",
    "        clfObj.fit(trgX, trgY)\n",
    "        pred = clfObj.predict(tstX)\n",
    "        d['test acc'].append(balanced_accuracy(tstY, pred))\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d.to_csv('./output/{}_{}_ILC.csv'.format(clf_type, dataset), index=False)\n",
    "    return\n",
    "    \n",
    "# Timing curve\n",
    "def plot_timing_curve(title, data_sizes, fit_times, predict_times, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Testing Size (% of total)\")\n",
    "    plt.ylabel(\"Time (s)\")\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "    predict_times_mean = np.mean(predict_times, axis=1)\n",
    "    predict_times_std = np.std(predict_times, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(data_sizes, fit_times_mean - fit_times_std,\n",
    "                     fit_times_mean + fit_times_std, alpha=0.2)\n",
    "    plt.fill_between(data_sizes, predict_times_mean - predict_times_std,\n",
    "                     predict_times_mean + predict_times_std, alpha=0.2)\n",
    "    plt.plot(data_sizes, predict_times_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Predict time\")\n",
    "    plt.plot(data_sizes, fit_times_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Fit time\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_timing_curve(X, Y, clf, clf_name, dataset):\n",
    "    out = defaultdict(dict)\n",
    "    print('Making timing curve for', dataset)\n",
    "    fracs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    for frac in fracs:  \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=frac, random_state=42)\n",
    "        st = time()\n",
    "        np.random.seed(55)\n",
    "        clf.fit(X_train, y_train)\n",
    "        out['train'][frac]= time() - st\n",
    "        st = time()\n",
    "        clf.predict(X_test)\n",
    "        out['test'][frac]= time() - st\n",
    "    out = pd.DataFrame(out)\n",
    "    out.to_csv('./output/{}_{}_timing.csv'.format(clf_name, dataset))\n",
    "    train_df = pd.DataFrame(out['train'], index=fracs)\n",
    "    test_df = pd.DataFrame(out['test'], fracs)\n",
    "    plt = plot_timing_curve('Timing Curve: {} - {}'.format(clf_name, dataset),\n",
    "                            np.array(fracs) * 100, \n",
    "                            train_df, test_df)\n",
    "    \n",
    "    plt.savefig('./output/images/{}_{}_TC.png'.format(clf_name, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_complexity_curve(title, param, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    best = pd.read_csv('./output/{}_{}_best.csv'.format(classifier, dataset))\n",
    "    best_params = ast.literal_eval(best.loc[0, 'params'])\n",
    "#     print(type(best_params['NN_ga__learning_rate']))\n",
    "    grid_search = pd.read_csv('./output/{}_{}_reg.csv'.format(classifier, dataset))\n",
    "#     print(grid_search['param_NN_ga__learning_rate'].dtype)\n",
    "#     print(grid_search['param_NN_ga__learning_rate'])\n",
    "    best_params.pop('{}__{}'.format(classifier, param))\n",
    "    for _param, value in best_params.items():\n",
    "        if isinstance(value, tuple):\n",
    "            grid_search['param_'+_param] = grid_search['param_'+_param].apply(ast.literal_eval)\n",
    "        grid_search = grid_search.loc[grid_search['param_'+_param] == value]\n",
    "#         print(_param, value, grid_search.iloc[0:2])\n",
    "\n",
    "    df = grid_search[['param_{}__{}'.format(classifier, param), \n",
    "                      'mean_test_score', \n",
    "                      'std_test_score', \n",
    "                      'mean_train_score', \n",
    "                      'std_train_score']].sort_values(by='param_{}__{}'.format(classifier, param))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores_mean = df['mean_train_score']\n",
    "    train_scores_std = df['std_train_score']\n",
    "    test_scores_mean = df['mean_test_score']\n",
    "    test_scores_std = df['std_test_score']\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(param_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2)\n",
    "    plt.fill_between(param_values, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2)\n",
    "    plt.plot(param_values, train_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores_mean, 'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_complexity_curve(clf_name, dataset, param):    \n",
    "    print('Making complexity curve for', dataset)\n",
    "    plt = plot_complexity_curve('Complexity Curve: {} - {} - {}'.format(clf_name, dataset, param),\n",
    "                                param,\n",
    "                                clf_name,\n",
    "                                dataset,\n",
    "                                ylim=None)\n",
    "\n",
    "    plt.savefig('./output/images/{}_{}_CC_{}.png'.format(clf_name, dataset, param), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "def plot_iteration_learning_curve(title, param, classifier, dataset, ylim=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "        \n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    df = pd.read_csv('./output/{}_{}_ILC.csv'.format(classifier, dataset))\n",
    "    param_values = df['param_{}__{}'.format(classifier, param)]\n",
    "    train_scores = df['train acc']\n",
    "    test_scores = df['test acc']\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.plot(param_values, train_scores, \n",
    "             'o-', linewidth=1, markersize=4,\n",
    "             label=\"Train\")\n",
    "    plt.plot(param_values, test_scores, \n",
    "             'o-', linewidth=1, markersize=4,\n",
    "             label=\"Test\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "def make_iteration_learning_curve(clf_name, dataset, param):    \n",
    "    print('Making iteration learning curve for', dataset)\n",
    "    plt = plot_iteration_learning_curve('Iteration Learning Curve: {} - {}'.format(clf_name, dataset),\n",
    "                                        param,\n",
    "                                        clf_name,\n",
    "                                        dataset,\n",
    "                                        ylim=None)\n",
    "\n",
    "    plt.savefig('./output/images/{}_{}_ILC.png'.format(clf_name, dataset), format='png', dpi=150)\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:  (4898, 12)\n",
      "Quality values:  Index(['bad', 'good'], dtype='object')\n",
      "Labels balance: \n",
      " bad     0.783585\n",
      "good    0.216415\n",
      "Name: quality_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Wine dataset\n",
    "\n",
    "wine = pd.read_csv('winequality-white.csv', sep = ';')\n",
    "print('Dataset shape: ', str(wine.shape))\n",
    "\n",
    "# There are no null values in the dataset\n",
    "\n",
    "# Creation of class for good vs bad wines (good when greater or equal than 7)\n",
    "wine['quality_label'] = 'bad'\n",
    "wine.loc[wine['quality']>=7, 'quality_label'] = 'good'\n",
    "wine['quality_label'] = wine['quality_label'].astype('category')\n",
    "\n",
    "print('Quality values: ', str(wine['quality_label'].cat.categories))\n",
    "print('Labels balance: \\n', wine['quality_label'].value_counts()/wine['quality_label'].size)\n",
    "\n",
    "wine['quality_int'] = wine['quality']\n",
    "wine['quality'] = wine['quality_label'].cat.codes\n",
    "\n",
    "wine = wine.drop(['quality_label', 'quality_int'], axis=1)\n",
    "wine = wine.astype(float)\n",
    "wine.quality = wine.quality.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data       \n",
    "wineX = wine.drop('quality', axis=1).values\n",
    "wineY = wine['quality'].values\n",
    "\n",
    "wine_trgX, wine_tstX, wine_trgY, wine_tstY = train_test_split(wineX, wineY, test_size=0.3, random_state=0, stratify=wineY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "class NeuralNetworkF(mlrose.NeuralNetwork):\n",
    "    def get_params(self, deep):\n",
    "        return {'hidden_nodes': self.hidden_nodes,\n",
    "                'max_iters': self.max_iters,\n",
    "                'bias': self.bias,\n",
    "                'is_classifier': self.is_classifier,\n",
    "                'learning_rate': self.lr,\n",
    "                'early_stopping': self.early_stopping,\n",
    "                'clip_max': self.clip_max,\n",
    "                'schedule': self.schedule,\n",
    "                'pop_size': self.pop_size,\n",
    "                'mutation_prob': self.mutation_prob}\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "nn_params = {'hidden_nodes': [22],\n",
    "             'activation': 'relu',\n",
    "             'bias': True,\n",
    "             'is_classifier': True,\n",
    "             'early_stopping': True,\n",
    "             'learning_rate': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for wine\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-1aa6e3da5220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n\u001b[0;32m---> 13\u001b[0;31m                         params_wine, 'NN_rhc', 'wine')        \n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmake_complexity_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN_rhc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-9150809dc192>\u001b[0m in \u001b[0;36mbasicResults\u001b[0;34m(clfObj, trgX, trgY, tstX, tstY, params, clf_type, dataset)\u001b[0m\n\u001b[1;32m     54\u001b[0m                      \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                      return_train_score=True)\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrgX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrgX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrgY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/francopiccolo/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Neural Networks random hill climb\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                  ('NN_rhc', NeuralNetworkF(algorithm='random_hill_climb',\n",
    "                                        **nn_params))])\n",
    "\n",
    "learning_rate = [10**x for x in np.arange(-4, 0, 1/2)]\n",
    "\n",
    "params_wine = {'NN_rhc__max_iters': [5000],\n",
    "               'NN_rhc__max_attempts': [50],\n",
    "               'NN_rhc__learning_rate': learning_rate}\n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'NN_rhc', 'wine')        \n",
    "\n",
    "make_complexity_curve('NN_rhc', 'wine', 'learning_rate')\n",
    "\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'NN_rhc', 'wine')\n",
    "\n",
    "max_iters = [2**x for x in range(14)]\n",
    "pipeW.set_params(**{'NN_rhc__early_stopping': False})    \n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'NN_rhc__max_iters': max_iters}, \n",
    "             'NN_rhc', 'wine')\n",
    "make_iteration_learning_curve('NN_rhc', 'wine', 'max_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for wine\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks simulated annealing\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                  ('NN_sa', NeuralNetworkF(algorithm='simulated_annealing',\n",
    "                                        **nn_params))])\n",
    "\n",
    "learning_rate = [10**x for x in np.arange(-4, 1/2, 1/2)]\n",
    "schedule = [mlrose.GeomDecay(), mlrose.ArithDecay(), mlrose.ExpDecay()]\n",
    "\n",
    "params_wine = {'NN_sa__max_iters': [5000],\n",
    "               'NN_sa__max_attempts': [50],\n",
    "               'NN_sa__learning_rate': learning_rate,\n",
    "               'NN_sa__schedule': schedule}\n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'NN_sa', 'wine')        \n",
    "\n",
    "make_complexity_curve('NN_sa', 'wine', 'learning_rate')\n",
    "\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'NN_sa', 'wine')\n",
    "\n",
    "# max_iters = [2**x for x in range(14)]\n",
    "max_iters = [2**x for x in range(12)]\n",
    "pipeW.set_params(**{'NN_sa__early_stopping': False})    \n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'NN_sa__max_iters': max_iters}, \n",
    "             'NN_sa', 'wine')\n",
    "make_iteration_learning_curve('NN_sa', 'wine', 'max_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating basic results for wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/sklearn/base.py:114: DeprecationWarning: Estimator NeuralNetworkF modifies parameters in __init__. This behavior is deprecated as of 0.18 and support for this behavior will be removed in 0.20.\n",
      "  % type(estimator).__name__, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making complexity curve for wine\n",
      "<class 'float'>\n",
      "float64\n",
      "0      0.000100\n",
      "1      0.000100\n",
      "2      0.000100\n",
      "3      0.000100\n",
      "4      0.000100\n",
      "5      0.000100\n",
      "6      0.000100\n",
      "7      0.000100\n",
      "8      0.000100\n",
      "9      0.000100\n",
      "10     0.000100\n",
      "11     0.000100\n",
      "12     0.000100\n",
      "13     0.000100\n",
      "14     0.000100\n",
      "15     0.000100\n",
      "16     0.000100\n",
      "17     0.000100\n",
      "18     0.000100\n",
      "19     0.000100\n",
      "20     0.000100\n",
      "21     0.000100\n",
      "22     0.000100\n",
      "23     0.000100\n",
      "24     0.000100\n",
      "25     0.000100\n",
      "26     0.000100\n",
      "27     0.000100\n",
      "28     0.000100\n",
      "29     0.000100\n",
      "         ...   \n",
      "290    0.316228\n",
      "291    0.316228\n",
      "292    0.316228\n",
      "293    0.316228\n",
      "294    0.316228\n",
      "295    0.316228\n",
      "296    0.316228\n",
      "297    0.316228\n",
      "298    0.316228\n",
      "299    0.316228\n",
      "300    0.316228\n",
      "301    0.316228\n",
      "302    0.316228\n",
      "303    0.316228\n",
      "304    0.316228\n",
      "305    0.316228\n",
      "306    0.316228\n",
      "307    0.316228\n",
      "308    0.316228\n",
      "309    0.316228\n",
      "310    0.316228\n",
      "311    0.316228\n",
      "312    0.316228\n",
      "313    0.316228\n",
      "314    0.316228\n",
      "315    0.316228\n",
      "316    0.316228\n",
      "317    0.316228\n",
      "318    0.316228\n",
      "319    0.316228\n",
      "Name: param_NN_ga__learning_rate, Length: 320, dtype: float64\n",
      "NN_ga__max_attempts 1    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.076938      0.029527         0.010627        0.004509   \n",
      "1       0.022620      0.007512         0.004727        0.004250   \n",
      "\n",
      "   param_NN_ga__learning_rate  param_NN_ga__max_attempts  \\\n",
      "0                      0.0001                          1   \n",
      "1                      0.0001                          1   \n",
      "\n",
      "   param_NN_ga__max_iters  param_NN_ga__mutation_prob  param_NN_ga__pop_size  \\\n",
      "0                      10                      0.0001                   10.0   \n",
      "1                      10                      0.0001                   32.0   \n",
      "\n",
      "                                              params       ...         \\\n",
      "0  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "1  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
      "0         0.486739        0.038924              196            0.510577   \n",
      "1         0.435883        0.056024              313            0.391526   \n",
      "\n",
      "   split1_train_score  split2_train_score  split3_train_score  \\\n",
      "0            0.511330            0.509932            0.510690   \n",
      "1            0.394098            0.389127            0.492972   \n",
      "\n",
      "   split4_train_score  mean_train_score  std_train_score  \n",
      "0            0.389923          0.486491         0.048286  \n",
      "1            0.498422          0.433229         0.051058  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "NN_ga__max_iters 10    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.076938      0.029527         0.010627        0.004509   \n",
      "1       0.022620      0.007512         0.004727        0.004250   \n",
      "\n",
      "   param_NN_ga__learning_rate  param_NN_ga__max_attempts  \\\n",
      "0                      0.0001                          1   \n",
      "1                      0.0001                          1   \n",
      "\n",
      "   param_NN_ga__max_iters  param_NN_ga__mutation_prob  param_NN_ga__pop_size  \\\n",
      "0                      10                      0.0001                   10.0   \n",
      "1                      10                      0.0001                   32.0   \n",
      "\n",
      "                                              params       ...         \\\n",
      "0  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "1  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
      "0         0.486739        0.038924              196            0.510577   \n",
      "1         0.435883        0.056024              313            0.391526   \n",
      "\n",
      "   split1_train_score  split2_train_score  split3_train_score  \\\n",
      "0            0.511330            0.509932            0.510690   \n",
      "1            0.394098            0.389127            0.492972   \n",
      "\n",
      "   split4_train_score  mean_train_score  std_train_score  \n",
      "0            0.389923          0.486491         0.048286  \n",
      "1            0.498422          0.433229         0.051058  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "NN_ga__mutation_prob 0.001     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "10       0.035625      0.016411         0.002893        0.001863   \n",
      "11       0.064623      0.032645         0.005881        0.005235   \n",
      "\n",
      "    param_NN_ga__learning_rate  param_NN_ga__max_attempts  \\\n",
      "10                      0.0001                          1   \n",
      "11                      0.0001                          1   \n",
      "\n",
      "    param_NN_ga__max_iters  param_NN_ga__mutation_prob  param_NN_ga__pop_size  \\\n",
      "10                      10                       0.001                   10.0   \n",
      "11                      10                       0.001                   32.0   \n",
      "\n",
      "                                               params       ...         \\\n",
      "10  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "11  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "\n",
      "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
      "10         0.466872        0.082065              274            0.381802   \n",
      "11         0.503792        0.048049              117            0.461290   \n",
      "\n",
      "    split1_train_score  split2_train_score  split3_train_score  \\\n",
      "10            0.399520            0.561984            0.489242   \n",
      "11            0.594858            0.511574            0.479618   \n",
      "\n",
      "    split4_train_score  mean_train_score  std_train_score  \n",
      "10            0.517283          0.469966         0.069012  \n",
      "11            0.562967          0.522061         0.050154  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "NN_ga__pop_size 1000.0     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "14       0.064601      0.069068          0.00988        0.011496   \n",
      "54       0.049580      0.020253          0.01016        0.006843   \n",
      "\n",
      "    param_NN_ga__learning_rate  param_NN_ga__max_attempts  \\\n",
      "14                    0.000100                          1   \n",
      "54                    0.000316                          1   \n",
      "\n",
      "    param_NN_ga__max_iters  param_NN_ga__mutation_prob  param_NN_ga__pop_size  \\\n",
      "14                      10                       0.001                 1000.0   \n",
      "54                      10                       0.001                 1000.0   \n",
      "\n",
      "                                               params       ...         \\\n",
      "14  {'NN_ga__learning_rate': 0.0001, 'NN_ga__max_a...       ...          \n",
      "54  {'NN_ga__learning_rate': 0.0003162300000000000...       ...          \n",
      "\n",
      "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
      "14         0.502759        0.051042              119            0.447017   \n",
      "54         0.429248        0.070071              315            0.400739   \n",
      "\n",
      "    split1_train_score  split2_train_score  split3_train_score  \\\n",
      "14            0.493634            0.588042            0.512627   \n",
      "54            0.431584            0.365480            0.518573   \n",
      "\n",
      "    split4_train_score  mean_train_score  std_train_score  \n",
      "14            0.473504          0.502965         0.047784  \n",
      "54            0.504481          0.444172         0.059009  \n",
      "\n",
      "[2 rows x 25 columns]\n",
      "Making timing curve for wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating iteration learning curve for  wine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n",
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/activation.py:77: RuntimeWarning: overflow encountered in exp\n",
      "  fx = 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making iteration learning curve for wine\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks Genetic Algorithm\n",
    "pipeW = Pipeline([('Scale', StandardScaler()),\n",
    "                  ('NN_ga', NeuralNetworkF(algorithm='genetic_alg',\n",
    "                                        **nn_params))])\n",
    "\n",
    "learning_rate = [round(10**x, 8) for x in np.arange(-4, 0, 1/2)]\n",
    "mutation_prob = [round(10**x, 8) for x in np.arange(-4, 0, 1/2)]\n",
    "pop_size = [round(10**x) for x in np.arange(1, 3.5, 1/2)]\n",
    "\n",
    "params_wine = {'NN_ga__max_iters': [5000],\n",
    "               'NN_ga__max_attempts': [50],\n",
    "               'NN_ga__learning_rate': learning_rate,\n",
    "               'NN_ga__pop_size': pop_size,\n",
    "               'NN_ga__mutation_prob': mutation_prob}\n",
    "\n",
    "wine_clf = basicResults(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "                        params_wine, 'NN_ga', 'wine')        \n",
    "\n",
    "make_complexity_curve('NN_ga', 'wine', 'learning_rate')\n",
    "\n",
    "wine_final_params = wine_clf.best_params_\n",
    "\n",
    "pipeW.set_params(**wine_final_params)\n",
    "make_timing_curve(wineX, wineY, pipeW, 'NN_ga', 'wine')\n",
    "\n",
    "max_iters = [2**x for x in range(14)]\n",
    "pipeW.set_params(**{'NN_ga__early_stopping': False})\n",
    "iterationLC(pipeW, wine_trgX, wine_trgY, wine_tstX, wine_tstY, \n",
    "            {'NN_ga__max_iters': max_iters}, \n",
    "             'NN_ga', 'wine')\n",
    "make_iteration_learning_curve('NN_ga', 'wine', 'max_iters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francopiccolo/anaconda3/lib/python3.6/site-packages/mlrose/algorithms.py:241: RuntimeWarning: overflow encountered in exp\n",
      "  prob = np.exp(delta_e/temp)\n"
     ]
    }
   ],
   "source": [
    "lengths = [2**x for x in range(4, 10)]\n",
    "results = pd.DataFrame(columns=['algorithm', 'length', 'iterations', 'time', 'fitness'])\n",
    "max_iters = [2**x for x in range(13)]\n",
    "max_attempts = [ceil(i/100) for i in max_iters]\n",
    "algorithms = ['sa', 'rhc', 'mimic', 'ga']\n",
    "problems = ['OneMax', 'FlipFlop', 'FourPeaks']\n",
    "\n",
    "for length in lengths:\n",
    "    for iteration, attempt in zip(max_iters, max_attempts):\n",
    "        for algorithm in algorithms:\n",
    "            for problem_name in problems:\n",
    "                \n",
    "                if problem_name == 'OneMax':                    \n",
    "                    fitness = mlrose.OneMax()\n",
    "                elif problem_name == 'FlipFlop': \n",
    "                    fitness = mlrose.FlipFlop()\n",
    "                elif problem_name == 'FourPeaks':\n",
    "                    fitness = mlrose.FourPeaks()\n",
    "                    \n",
    "                problem = mlrose.DiscreteOpt(length=length,\n",
    "                                             fitness_fn=fitness,\n",
    "                                             maximize=True, \n",
    "                                             max_val=2)\n",
    "                \n",
    "                init_state = np.random.randint(0, 2, length)\n",
    "                \n",
    "                ti = time()\n",
    "                if algorithm == 'sa':\n",
    "                    schedule = mlrose.ExpDecay()  \n",
    "                    _, fitness = mlrose.simulated_annealing(problem,\n",
    "                                                            schedule=schedule,\n",
    "                                                            max_attempts=attempt,\n",
    "                                                            max_iters=iteration,\n",
    "                                                            init_state=init_state)\n",
    "\n",
    "                elif algorithm == 'rhc':\n",
    "                    _, fitness = mlrose.random_hill_climb(problem, \n",
    "                                                          max_attempts=attempt, \n",
    "                                                          max_iters=iteration, \n",
    "                                                          restarts=0, \n",
    "                                                          init_state=init_state)\n",
    "\n",
    "                elif algorithm == 'ga':\n",
    "                    if iteration < 2000:\n",
    "                        _, fitness = mlrose.genetic_alg(problem, \n",
    "                                                        pop_size=200, \n",
    "                                                        mutation_prob=0.1, \n",
    "                                                        max_attempts=attempt, \n",
    "                                                        max_iters=iteration)\n",
    "                    else:\n",
    "                        fitness = 0\n",
    "                        \n",
    "                elif algorithm == 'mimic':\n",
    "                    if iteration < 50:\n",
    "                        _, fitness = mlrose.mimic(problem, \n",
    "                                                  pop_size=200, \n",
    "                                                  keep_pct=0.2, \n",
    "                                                  max_attempts=attempt, \n",
    "                                                  max_iters=iteration)\n",
    "                    else: \n",
    "                        fitness = 0\n",
    "                        \n",
    "                tf = time()\n",
    "                results = results.append(pd.Series({'problem': problem_name,\n",
    "                                                    'algorithm': algorithm,\n",
    "                                                    'length': length,\n",
    "                                                    'iterations': iteration,\n",
    "                                                    'time': tf-ti,\n",
    "                                                    'fitness': fitness}),\n",
    "                                         ignore_index=True)\n",
    "results.to_csv('./output/opt_results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
